{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMA-943Aev9e"
   },
   "source": [
    "# Spiking multicompartment PC network\n",
    "\n",
    "## Abstract\n",
    "Predictive coding is a promising theoretical framework for understanding the hierarchical sensory processing in the brain, yet how it is implemented with cortical spiking neurons is still unclear. While most existing works have taken a hand-wiring approach to creating microcircuits which match experimental results, recent work in applying the optimisation approach revealed that cortical connectivity might result from self-organisation given some fundamental computational principle, ie. energy efficiency. We thus investigated whether predictive coding properties in a multicompartment spiking neural network can result from energy optimisation. We found that only the model trained with an energy objective in addition to a task-relevant objective was able to reconstruct internal representations given top-down expectation signals alone. Neurons in the energy-optimised model also showed differential responses to expected vs unexpected stimuli, qualitatively similar to experimental evidence for predictive coding. These findings indicated that predictive-coding-like behaviour might be an emergent property of energy optimisation, providing a new perspective on how predictive coding could be achieved in the cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e5fUxmZcxfc",
    "outputId": "87a4b8e1-ab15-4a24-dc7e-20a6796837c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set seed\n",
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RlhsaGdOj55t"
   },
   "outputs": [],
   "source": [
    "## Utils\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, prefix, filename='_rec2_bias_checkpoint.pth.tar'):\n",
    "    print('saving at ', prefix + filename)\n",
    "    torch.save(state, prefix + filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(prefix + filename, prefix + '_rec2_bias_model_best.pth.tar')\n",
    "\n",
    "\n",
    "def model_result_dict_load(fn):\n",
    "    \"\"\"load tar file with saved model\n",
    "\n",
    "    Args:\n",
    "        fn (str): tar file name\n",
    "\n",
    "    Returns:\n",
    "        dict: dictornary containing saved results\n",
    "    \"\"\"\n",
    "    with open(fn, 'rb') as f:\n",
    "        dict = torch.load(f)\n",
    "    return dict\n",
    "\n",
    "def save_model(model_name,model):\n",
    "    torch.save(model,\"{}_model.pth\".format(model_name))\n",
    "    torch.save(model.state_dict(),\"{}_state_dict.pth\".format(model_name))\n",
    "\n",
    "def load_model(model_name):\n",
    "    model=torch.load(\".\\\\{}_model.pth\".format(model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p7KkVxPfe8q"
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNZglAYUfXQF",
    "outputId": "1e81f699-656e-425f-b289-71eeff15ab2a"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "traindata = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testdata = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "# data loading\n",
    "train_loader = torch.utils.data.DataLoader(traindata, batch_size=batch_size,\n",
    "                                           shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfP3cI8BfnoK"
   },
   "source": [
    "## Surrogate gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1KJqRTDNgaqj"
   },
   "outputs": [],
   "source": [
    "\n",
    "b_j0 = 0.1  # neural threshold baseline\n",
    "\n",
    "R_m = 3  # membrane resistance\n",
    "gamma = .5  # gradient scale\n",
    "lens = 0.5\n",
    "\n",
    "\n",
    "def gaussian(x, mu=0., sigma=.5):\n",
    "    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(math.pi)) / sigma\n",
    "\n",
    "\n",
    "class ActFun_adp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):  # input = membrane potential- threshold\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(0).float()  # is firing ???\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # approximate the gradients\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        # temp = abs(input) < lens\n",
    "        scale = 6.0\n",
    "        hight = .15\n",
    "        # temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(math.pi))/lens\n",
    "        temp = gaussian(input, mu=0., sigma=lens) * (1. + hight) \\\n",
    "               - gaussian(input, mu=lens, sigma=scale * lens) * hight \\\n",
    "               - gaussian(input, mu=-lens, sigma=scale * lens) * hight\n",
    "        # temp =  gaussian(input, mu=0., sigma=lens)\n",
    "        return grad_input * temp.float() * gamma\n",
    "        # return grad_input\n",
    "\n",
    "\n",
    "act_fun_adp = ActFun_adp.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gAwZBV_5gKUS"
   },
   "outputs": [],
   "source": [
    "# layers\n",
    "def shifted_sigmoid(currents):\n",
    "    return (1 / (1 + torch.exp(-currents)) - 0.5)/2\n",
    "\n",
    "\n",
    "class SnnLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dim: int,\n",
    "            is_rec: bool,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            tau_m_init=15.,\n",
    "            tau_adap_init=20,\n",
    "            tau_a_init=15.,\n",
    "            dt = 0.5,\n",
    "            bias = True\n",
    "    ):\n",
    "        super(SnnLayer, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.is_rec = is_rec\n",
    "        self.is_adapt = is_adapt\n",
    "        self.one_to_one = one_to_one\n",
    "        self.dt = dt\n",
    "\n",
    "        if is_rec:\n",
    "            self.rec_w = nn.Linear(hidden_dim, hidden_dim, bias=bias)\n",
    "            # init weights\n",
    "            if bias:\n",
    "                nn.init.constant_(self.rec_w.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.rec_w.weight)\n",
    "\n",
    "            p = torch.full(self.rec_w.weight.size(), fill_value=0.5).to(device)\n",
    "            self.weight_mask = torch.bernoulli(p)\n",
    "\n",
    "        else:\n",
    "            self.fc_weights = nn.Linear(in_dim, hidden_dim, bias=bias)\n",
    "            if bias:\n",
    "                nn.init.constant_(self.fc_weights.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.fc_weights.weight)\n",
    "\n",
    "        # define param for time constants\n",
    "        self.tau_adp = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_m = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_a = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        nn.init.normal_(self.tau_adp, tau_adap_init, .1)\n",
    "        nn.init.normal_(self.tau_m, tau_m_init, .1)\n",
    "        nn.init.normal_(self.tau_a, tau_a_init, .1)\n",
    "\n",
    "        # self.tau_adp = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_m = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_a = nn.Parameter(torch.Tensor(1))\n",
    "\n",
    "        # nn.init.constant_(self.tau_adp, tau_adap_init)\n",
    "        # nn.init.constant_(self.tau_m, tau_m_init)\n",
    "        # nn.init.constant_(self.tau_a, tau_a_init)\n",
    "\n",
    "        # nn.init.normal_(self.tau_adp, 200., 20.)\n",
    "        # nn.init.normal_(self.tau_m, 20., .5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def mem_update(self, ff, fb, soma, spike, a_curr, b, is_adapt, baseline_thre=b_j0, r_m=3):\n",
    "        \"\"\"\n",
    "        mem update for each layer of neurons\n",
    "        :param ff: feedforward signal\n",
    "        :param fb: feedback signal to apical tuft\n",
    "        :param soma: mem voltage potential at soma\n",
    "        :param spike: spiking at last time step\n",
    "        :param a_curr: apical tuft current at last t\n",
    "        :param current: input current at last t\n",
    "        :param b: adaptive threshold\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # alpha = self.sigmoid(self.tau_m)\n",
    "        # rho = self.sigmoid(self.tau_adp)\n",
    "        # eta = self.sigmoid(self.tau_a)\n",
    "        alpha = torch.exp(-self.dt/self.tau_m)\n",
    "        rho = torch.exp(-self.dt/self.tau_adp)\n",
    "        eta = torch.exp(-self.dt/self.tau_a)\n",
    "\n",
    "        if is_adapt:\n",
    "            beta = 1.8\n",
    "        else:\n",
    "            beta = 0.\n",
    "\n",
    "        b = rho * b + (1 - rho) * spike  # adaptive contribution\n",
    "        new_thre = baseline_thre + beta * b  # udpated threshold\n",
    "        \n",
    "        current_new = ff \n",
    "\n",
    "        a_new = eta * a_curr + fb  # fb into apical tuft\n",
    "\n",
    "        #print(\"mem update\",current_decay , current_curr , ff, eta , a_curr , fb)\n",
    "        \n",
    "        soma_new = alpha * soma + shifted_sigmoid(a_new) + current_new - new_thre * spike\n",
    "        # soma_new = alpha * soma + shifted_sigmoid(a_new) + rise * ff - new_thre * spike\n",
    "        # soma_new = alpha * soma + 1/2 * (a_new) + ffs - new_thre * spike\n",
    "\n",
    "        inputs_ = soma_new - new_thre\n",
    "\n",
    "        spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
    "        # mem = (1 - spike) * mem\n",
    "\n",
    "        return soma_new, spike, a_new, new_thre, b\n",
    "\n",
    "    def forward(self, ff, fb, soma_t, spk_t, a_curr_t, b_t):\n",
    "        \"\"\"\n",
    "        forward function of a single layer. given previous neuron states and current input, update neuron states\n",
    "\n",
    "        :param ff: ff signal (not counting rec)\n",
    "        :param fb: fb top down signal\n",
    "        :param soma_t: soma voltage\n",
    "        :param a_curr_t: apical tuft voltage\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if self.is_rec:\n",
    "            self.rec_w.weight.data = self.rec_w.weight.data * self.weight_mask\n",
    "            # self.rec_w.weight.data = (self.rec_w.weight.data < 0).float() * self.rec_w.weight.data\n",
    "            r_in = ff + self.rec_w(spk_t)\n",
    "        else:\n",
    "            if self.one_to_one:\n",
    "                r_in = ff\n",
    "            else:\n",
    "                r_in = self.fc_weights(ff)\n",
    "\n",
    "        soma_t1, spk_t1, a_curr_t1, _, b_t1 = self.mem_update(r_in, fb, soma_t, spk_t, a_curr_t, b_t, self.is_adapt)\n",
    "\n",
    "        return soma_t1, spk_t1, a_curr_t1, b_t1\n",
    "\n",
    "\n",
    "class SnnLayerRiseTime(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dim: int,\n",
    "            is_rec: bool,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            tau_m_init=15.,\n",
    "            tau_curr_decay_init=10.,\n",
    "            tau_adap_init=20,\n",
    "            tau_a_init=15.,\n",
    "            dt = 0.5,\n",
    "            bias = True\n",
    "    ):\n",
    "        super(SnnLayerRiseTime, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.is_rec = is_rec\n",
    "        self.is_adapt = is_adapt\n",
    "        self.one_to_one = one_to_one\n",
    "        self.dt = dt\n",
    "\n",
    "        if is_rec:\n",
    "            self.rec_w = nn.Linear(hidden_dim, hidden_dim, bias=bias)\n",
    "            # init weights\n",
    "            if bias:\n",
    "                nn.init.constant_(self.rec_w.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.rec_w.weight)\n",
    "\n",
    "            p = torch.full(self.rec_w.weight.size(), fill_value=0.5).to(device)\n",
    "            self.weight_mask = torch.bernoulli(p)\n",
    "\n",
    "        else:\n",
    "            self.fc_weights = nn.Linear(in_dim, hidden_dim, bias=bias)\n",
    "            if bias:\n",
    "                nn.init.constant_(self.fc_weights.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.fc_weights.weight)\n",
    "\n",
    "        # define param for time constants\n",
    "        self.tau_adp = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_m = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_curr_decay = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_a = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        nn.init.normal_(self.tau_adp, tau_adap_init, .1)\n",
    "        nn.init.normal_(self.tau_m, tau_m_init, .1)\n",
    "        nn.init.normal_(self.tau_curr_decay, tau_curr_decay_init, .1)\n",
    "        nn.init.normal_(self.tau_a, tau_a_init, .1)\n",
    "\n",
    "        # self.tau_adp = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_m = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_a = nn.Parameter(torch.Tensor(1))\n",
    "\n",
    "        # nn.init.constant_(self.tau_adp, tau_adap_init)\n",
    "        # nn.init.constant_(self.tau_m, tau_m_init)\n",
    "        # nn.init.constant_(self.tau_a, tau_a_init)\n",
    "\n",
    "        # nn.init.normal_(self.tau_adp, 200., 20.)\n",
    "        # nn.init.normal_(self.tau_m, 20., .5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def mem_update(self, ff, fb, soma, spike, a_curr, current_curr, b, is_adapt, baseline_thre=b_j0, r_m=3):\n",
    "        \"\"\"\n",
    "        mem update for each layer of neurons\n",
    "        :param ff: feedforward signal\n",
    "        :param fb: feedback signal to apical tuft\n",
    "        :param soma: mem voltage potential at soma\n",
    "        :param spike: spiking at last time step\n",
    "        :param a_curr: apical tuft current at last t\n",
    "        :param current: input current at last t\n",
    "        :param b: adaptive threshold\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # alpha = self.sigmoid(self.tau_m)\n",
    "        # rho = self.sigmoid(self.tau_adp)\n",
    "        # eta = self.sigmoid(self.tau_a)\n",
    "        alpha = torch.exp(-self.dt/self.tau_m)\n",
    "        current_decay = torch.exp(-self.dt/self.tau_curr_decay)\n",
    "        rho = torch.exp(-self.dt/self.tau_adp)\n",
    "        eta = torch.exp(-self.dt/self.tau_a)\n",
    "\n",
    "        if is_adapt:\n",
    "            beta = 1.8\n",
    "        else:\n",
    "            beta = 0.\n",
    "                \n",
    "        b = rho * b + (1 - rho) * spike  # adaptive contribution\n",
    "        new_thre = baseline_thre + beta * b  # udpated threshold\n",
    "        \n",
    "        current_new = current_decay * current_curr + ff\n",
    "\n",
    "        a_new = eta * a_curr + fb  # fb into apical tuft\n",
    "\n",
    "        #print(\"mem update\",current_decay , current_curr , ff, eta , a_curr , fb)\n",
    "        \n",
    "        soma_new = alpha * soma + shifted_sigmoid(a_new) + current_new - new_thre * spike\n",
    "        # soma_new = alpha * soma + shifted_sigmoid(a_new) + rise * ff - new_thre * spike\n",
    "        # soma_new = alpha * soma + 1/2 * (a_new) + ffs - new_thre * spike\n",
    "\n",
    "        inputs_ = soma_new - new_thre\n",
    "\n",
    "        spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
    "        # mem = (1 - spike) * mem\n",
    "\n",
    "        return soma_new, spike, a_new, current_new, new_thre, b\n",
    "\n",
    "    def forward(self, ff, fb, soma_t, spk_t, a_curr_t, current_curr_t, b_t):\n",
    "        \"\"\"\n",
    "        forward function of a single layer. given previous neuron states and current input, update neuron states\n",
    "\n",
    "        :param ff: ff signal (not counting rec)\n",
    "        :param fb: fb top down signal\n",
    "        :param soma_t: soma voltage\n",
    "        :param a_curr_t: apical tuft voltage\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if self.is_rec:\n",
    "            self.rec_w.weight.data = self.rec_w.weight.data * self.weight_mask\n",
    "            # self.rec_w.weight.data = (self.rec_w.weight.data < 0).float() * self.rec_w.weight.data\n",
    "            r_in = ff + self.rec_w(spk_t)\n",
    "        else:\n",
    "            if self.one_to_one:\n",
    "                r_in = ff\n",
    "            else:\n",
    "                r_in = self.fc_weights(ff)\n",
    "\n",
    "        soma_t1, spk_t1, a_curr_t1, current_curr_t1, _, b_t1 = self.mem_update(r_in, fb, soma_t, spk_t, a_curr_t, current_curr_t, b_t, self.is_adapt)\n",
    "\n",
    "        return soma_t1, spk_t1, a_curr_t1, current_curr_t1, b_t1\n",
    "        \n",
    "class OutputLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            out_dim: int,\n",
    "            is_fc: bool,\n",
    "            tau_fixed=None,\n",
    "            bias = True,\n",
    "            dt=0.5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        output layer class\n",
    "        :param is_fc: whether integrator is fc to r_out in rec or not\n",
    "        \"\"\"\n",
    "        super(OutputLayer, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.is_fc = is_fc\n",
    "        self.dt = dt\n",
    "\n",
    "        if is_fc:\n",
    "            self.fc = nn.Linear(in_dim, out_dim, bias=bias)\n",
    "            if bias:\n",
    "                nn.init.constant_(self.fc.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "        # tau_m\n",
    "        if tau_fixed is None:\n",
    "            self.tau_m = nn.Parameter(torch.Tensor(out_dim))\n",
    "            nn.init.constant_(self.tau_m, 5)\n",
    "        else:\n",
    "            self.tau_m = nn.Parameter(torch.Tensor(out_dim), requires_grad=False)\n",
    "            nn.init.constant_(self.tau_m, tau_fixed)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x_t, mem_t):\n",
    "        \"\"\"\n",
    "        integrator neuron without spikes\n",
    "        \"\"\"\n",
    "        alpha = torch.exp(-self.dt/self.tau_m)\n",
    "        # alpha = self.sigmoid(self.tau_m)\n",
    "\n",
    "        if self.is_fc:\n",
    "            x_t = self.fc(x_t)\n",
    "        else:\n",
    "            x_t = x_t.view(-1, 10, int(self.in_dim / 10)).mean(dim=2)  # sum up population spike\n",
    "\n",
    "        # d_mem = -soma_t + x_t\n",
    "        mem = (mem_t + x_t) * alpha\n",
    "        # mem = alpha * soma_t + (1 - alpha) * x_t\n",
    "        return mem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Hpf_RNkHfknR"
   },
   "outputs": [],
   "source": [
    "# 2 hidden layers\n",
    "class Decorrelation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decorrelation, self).__init__()\n",
    "        self.decorr_matrix_next = None\n",
    "    \n",
    "    def forward(self, input, decorr_matrix_prev_batch):\n",
    "        n=1e-3\n",
    "        diag = torch.diag_embed(torch.square(input)) # (batch_size,hidden_dim,hidden_dim)\n",
    "\n",
    "        input = input.reshape(input.shape[0],input.shape[1],1) # (batch_size,hidden_dim,1)\n",
    "        input = torch.matmul(decorr_matrix_prev_batch, input) # (batch_size,hidden_dim,1)\n",
    "\n",
    "        mult = torch.matmul(input, torch.transpose(input,1,2)) # (batch_size,hidden_dim,hidden_dim)\n",
    "        update = torch.mean(mult - diag, dim=0) # (hidden_dim,hidden_dim)\n",
    "        self.decorr_matrix_next = decorr_matrix_prev_batch - n * torch.matmul(update, decorr_matrix_prev_batch) # (hidden_dim,hidden_dim)\n",
    "\n",
    "        input = input.reshape(input.shape[0],input.shape[1]) # (batch_size,hidden_dim)\n",
    "        return input\n",
    "        \n",
    "class SnnNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dims: list,\n",
    "            out_dim: int,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            dp_rate: float,\n",
    "            is_rec: bool,\n",
    "            rise_time: bool,\n",
    "            bias = True\n",
    "    ):\n",
    "        super(SnnNetwork, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.out_dim = out_dim\n",
    "        self.is_adapt = is_adapt\n",
    "        self.one_to_one = one_to_one\n",
    "        self.is_rec = is_rec\n",
    "        self.rise_time = rise_time\n",
    "        self.dp = nn.Dropout(dp_rate)\n",
    "\n",
    "        if self.rise_time:\n",
    "            self.layer1 = SnnLayerRiseTime(hidden_dims[0], hidden_dims[0], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "        else:\n",
    "            self.layer1 = SnnLayer(hidden_dims[0], hidden_dims[0], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "\n",
    "        # r in to r out\n",
    "        self.layer1to2 = nn.Linear(hidden_dims[0], hidden_dims[1], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer1to2.weight)\n",
    "\n",
    "        # r out to r in\n",
    "        self.layer2to1 = nn.Linear(hidden_dims[1], hidden_dims[0], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer2to1.weight)\n",
    "\n",
    "        if self.rise_time:\n",
    "            self.layer2 = SnnLayerRiseTime(hidden_dims[1], hidden_dims[1], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "        else:\n",
    "            self.layer2 = SnnLayer(hidden_dims[1], hidden_dims[1], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "\n",
    "        self.output_layer = OutputLayer(hidden_dims[1], out_dim, is_fc=True, bias=bias)\n",
    "\n",
    "        self.out2layer2 = nn.Linear(out_dim, hidden_dims[1], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.out2layer2.weight)\n",
    "\n",
    "        if bias:\n",
    "            nn.init.constant_(self.layer1to2.bias, 0)\n",
    "            nn.init.constant_(self.layer2to1.bias, 0)\n",
    "            nn.init.constant_(self.out2layer2.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "        self.fr_layer2 = 0\n",
    "        self.fr_layer1 = 0\n",
    "\n",
    "        self.error1 = 0\n",
    "        self.error2 = 0\n",
    "\n",
    "    def forward(self, x_t, h):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t*0.5)\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "\n",
    "        soma_1, spk_1, a_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[5]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], b_t=h[3])\n",
    "\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.out2layer2(F.normalize(h[-1], dim=1)), soma_t=h[4],\n",
    "                                                   spk_t=h[5], a_curr_t=h[6], b_t=h[7])\n",
    "\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_2, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, b_2,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "\n",
    "        return log_softmax, h\n",
    "\n",
    "    def inference(self, x_t, h, T, bystep=None):\n",
    "        \"\"\"\n",
    "        only called during inference\n",
    "        :param x_t: input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param bystep: if true, then x_t is a sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "\n",
    "            if bystep is None:\n",
    "                log_softmax, h = self.forward(x_t, h)\n",
    "            else:\n",
    "                log_softmax, h = self.forward(x_t[t], h)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h)\n",
    "            \n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def inference_rise_time(self, x_t, h, T, bystep=None):\n",
    "        \"\"\"\n",
    "        only called during inference\n",
    "        :param x_t: input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param bystep: if true, then x_t is a sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "\n",
    "            if bystep is None:\n",
    "                log_softmax, h = self.forward_rise_time(x_t, h)\n",
    "            else:\n",
    "                log_softmax, h = self.forward_rise_time(x_t[t], h)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h)\n",
    "            \n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def clamped_generate(self, test_class, zeros, h_clamped, T, clamp_value=0.5, batch=False, noise=None):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param zeros: input containing zeros, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if not batch:\n",
    "                h_clamped[-1][0] = -clamp_value\n",
    "                h_clamped[-1][0, test_class] = clamp_value\n",
    "            else:\n",
    "                h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                    h_clamped[-1][:] += noise\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = self.forward(zeros, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def clamped_generate_rise_time(self, test_class, zeros, h_clamped, T, clamp_value=0.5, batch=False, noise=None):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param zeros: input containing zeros, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if not batch:\n",
    "                h_clamped[-1][0] = -clamp_value\n",
    "                h_clamped[-1][0, test_class] = clamp_value\n",
    "            else:\n",
    "                h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                    h_clamped[-1][:] += noise\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = self.forward_rise_time(zeros, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist\n",
    "        \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            # r\n",
    "            weight.new(bsz, self.hidden_dims[0]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # p\n",
    "            weight.new(bsz, self.hidden_dims[1]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "\n",
    "\n",
    "# 3 hidden layers\n",
    "\n",
    "class SnnNetwork3Layer(SnnNetwork):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dims: list,\n",
    "            out_dim: int,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            dp_rate: float,\n",
    "            is_rec: bool,\n",
    "            rise_time: bool,\n",
    "            bias = True\n",
    "    ):\n",
    "        super().__init__(in_dim, hidden_dims, out_dim, is_adapt, one_to_one, dp_rate, is_rec, rise_time)\n",
    "\n",
    "        # decorrelation\n",
    "        self.decorr_layer_0 = Decorrelation()\n",
    "        self.decorr_layer_1 = Decorrelation()\n",
    "        self.decorr_layer_2 = Decorrelation()\n",
    "        self.decorr_layer_3 = Decorrelation()\n",
    "        self.decorr_layer_4 = Decorrelation()\n",
    "\n",
    "        if self.rise_time:\n",
    "            self.layer3 = SnnLayerRiseTime(hidden_dims[2], hidden_dims[2], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "        else:\n",
    "            self.layer3 = SnnLayer(hidden_dims[2], hidden_dims[2], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "            \n",
    "        self.layer2to3 = nn.Linear(hidden_dims[1], hidden_dims[2], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer2to3.weight)\n",
    "\n",
    "        # r out to r in\n",
    "        self.layer3to2 = nn.Linear(hidden_dims[2], hidden_dims[1], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer3to2.weight)\n",
    "\n",
    "        self.output_layer = OutputLayer(hidden_dims[2], out_dim, is_fc=True)\n",
    "\n",
    "        self.out2layer3 = nn.Linear(out_dim, hidden_dims[2], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.out2layer3.weight)\n",
    "\n",
    "        self.fr_layer3 = 0\n",
    "\n",
    "        self.error3 = 0\n",
    "\n",
    "        self.input_fc = nn.Linear(in_dim, hidden_dims[0], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.input_fc.weight)\n",
    "\n",
    "        if bias:\n",
    "            nn.init.constant_(self.layer2to3.bias, 0)\n",
    "            nn.init.constant_(self.layer3to2.bias, 0)\n",
    "            nn.init.constant_(self.out2layer3.bias, 0)\n",
    "            nn.init.constant_(self.input_fc.bias, 0)\n",
    "            print('bias set to 0')\n",
    "\n",
    "    def forward_rise_time(self, x_t, h):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t)\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "        x_t = self.input_fc(x_t)\n",
    "\n",
    "        soma_1, spk_1, a_curr_1, current_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[6]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], current_curr_t=h[3], b_t=h[4])\n",
    "\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, current_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.layer3to2(h[11]), soma_t=h[5],\n",
    "                                                   spk_t=h[6], a_curr_t=h[7], current_curr_t=h[8], b_t=h[9])\n",
    "\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        soma_3, spk_3, a_curr_3, current_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=self.out2layer3(F.normalize(h[-1], dim=1)), soma_t=h[10],\n",
    "                                                   spk_t=h[11], a_curr_t=h[12], current_curr_t=h[13], b_t=h[14])\n",
    "        # soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=0, soma_t=h[8],\n",
    "        #                                            spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "\n",
    "        self.error3 = a_curr_3 - soma_3\n",
    "\n",
    "        self.fr_layer3 = self.fr_layer3 + spk_3.detach().cpu().numpy().mean()\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_3, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, current_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, current_curr_2, b_2,\n",
    "             soma_3, spk_3, a_curr_3, current_curr_3, b_3,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "\n",
    "        return log_softmax, h\n",
    "\n",
    "    def forward(self, x_t, h):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t)\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "        x_t = self.input_fc(x_t)\n",
    "\n",
    "        soma_1, spk_1, a_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[5]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], b_t=h[3])\n",
    "\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.layer3to2(h[9]), soma_t=h[4],\n",
    "                                                   spk_t=h[5], a_curr_t=h[6], b_t=h[7])\n",
    "\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=self.out2layer3(F.normalize(h[-1], dim=1)), soma_t=h[8],\n",
    "                                                   spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "        # soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=0, soma_t=h[8],\n",
    "        #                                            spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "\n",
    "        self.error3 = a_curr_3 - soma_3\n",
    "\n",
    "        self.fr_layer3 = self.fr_layer3 + spk_3.detach().cpu().numpy().mean()\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_3, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, b_2,\n",
    "             soma_3, spk_3, a_curr_3, b_3,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "\n",
    "        return log_softmax, h\n",
    "        \n",
    "    def forward_decorrelation(self, x_t, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t)\n",
    "\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "\n",
    "        # decorrelate input\n",
    "        x_t = self.decorr_layer_0(x_t, decorr_matrix_0)\n",
    "        decorr_matrix_0 = self.decorr_layer_0.decorr_matrix_next.data.clone()\n",
    "        x_t = self.input_fc(x_t)\n",
    "\n",
    "        # decorrelate input to L1\n",
    "        x_t = self.decorr_layer_1(x_t, decorr_matrix_1)\n",
    "        decorr_matrix_1 = self.decorr_layer_1.decorr_matrix_next.data.clone()\n",
    "        \n",
    "        soma_1, spk_1, a_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[5]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], b_t=h[3])\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # decorrelate input to L2\n",
    "        spk_1 = self.decorr_layer_2(spk_1, decorr_matrix_2)\n",
    "        decorr_matrix_2 = self.decorr_layer_2.decorr_matrix_next.data.clone()\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.layer3to2(h[9]), soma_t=h[4],\n",
    "                                                   spk_t=h[5], a_curr_t=h[6], b_t=h[7])\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        # decorrelate input to L3\n",
    "        spk_2 = self.decorr_layer_3(spk_2, decorr_matrix_3)\n",
    "        decorr_matrix_3 = self.decorr_layer_3.decorr_matrix_next.data.clone()\n",
    "\n",
    "        soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=self.out2layer3(F.normalize(h[-1], dim=1)), soma_t=h[8],\n",
    "                                                   spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "        self.error3 = a_curr_3 - soma_3\n",
    "\n",
    "        # decorrelate input to output layer\n",
    "        spk_3 = self.decorr_layer_4(spk_3, decorr_matrix_4)\n",
    "        decorr_matrix_4 = self.decorr_layer_4.decorr_matrix_next.data.clone()\n",
    "        \n",
    "        self.fr_layer3 = self.fr_layer3 + spk_3.detach().cpu().numpy().mean()\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_3, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, b_2,\n",
    "             soma_3, spk_3, a_curr_3, b_3,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "        return log_softmax, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4\n",
    "\n",
    "    def inference_decorrelation(self, x_t, h, T, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4, bystep=None):\n",
    "        \"\"\"\n",
    "        only called during inference\n",
    "        :param x_t: input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param bystep: if true, then x_t is a sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "\n",
    "            if bystep is None:\n",
    "                log_softmax, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4 = self.forward_decorrelation(x_t, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "            else:\n",
    "                log_softmax, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4 = self.forward_decorrelation(x_t[t], h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h)\n",
    "            \n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def init_hidden_rise_time(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        return (\n",
    "            # l1\n",
    "            weight.new(bsz, self.hidden_dims[0]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # l2\n",
    "            weight.new(bsz, self.hidden_dims[1]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # l3\n",
    "            weight.new(bsz, self.hidden_dims[2]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        return (\n",
    "            # l1\n",
    "            weight.new(bsz, self.hidden_dims[0]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # l2\n",
    "            weight.new(bsz, self.hidden_dims[1]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # l3\n",
    "            weight.new(bsz, self.hidden_dims[2]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "        \n",
    "    def init_hidden_allzero(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            # l1\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # l2\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # l3\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "\n",
    "    def clamp_withnoise(self, test_class, zeros, h_clamped, T, noise, index, batch=False, clamp_value=0.5):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param zeros: input containing zeros, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param noise: noise values\n",
    "        :param index: index in h where noise is added to\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if not batch:\n",
    "                h_clamped[-1][0] = -clamp_value\n",
    "                h_clamped[-1][0, test_class] = clamp_value\n",
    "            else:\n",
    "                h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                h_clamped[index][:, :] += noise * h_clamped[index][:, :]\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = self.forward(zeros, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8p3rNn-kPx7"
   },
   "source": [
    "## FTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VOFtn6gOkPfk"
   },
   "outputs": [],
   "source": [
    "alpha = .2\n",
    "beta = .5\n",
    "rho = 0.\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_stats_named_params(model):\n",
    "    named_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        sm, lm, dm = param.detach().clone(), 0.0 * param.detach().clone(), 0.0 * param.detach().clone()\n",
    "        named_params[name] = (param, sm, lm, dm)\n",
    "    return named_params\n",
    "\n",
    "\n",
    "def post_optimizer_updates(named_params):\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        lm.data.add_(-alpha * (param - sm))\n",
    "        sm.data.mul_((1.0 - beta))\n",
    "        sm.data.add_(beta * param - (beta / alpha) * lm)\n",
    "\n",
    "\n",
    "def get_regularizer_named_params(named_params, _lambda=1.0):\n",
    "    regularization = torch.zeros([], device=device)\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        regularization += (rho - 1.) * torch.sum(param * lm)\n",
    "        r_p = _lambda * 0.5 * alpha * torch.sum(torch.square(param - sm))\n",
    "        regularization += r_p\n",
    "        # print(name,r_p)\n",
    "    return regularization\n",
    "\n",
    "\n",
    "def reset_named_params(named_params):\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        param.data.copy_(sm.data)\n",
    "\n",
    "\n",
    "def train_fptt(epoch, batch_size, log_interval,\n",
    "               train_loader, model, named_params,\n",
    "               time_steps, k_updates, omega, optimizer,\n",
    "               clf_alpha, energy_alpha, spike_alpha, clip, lr, rise_time):\n",
    "    train_loss = 0\n",
    "    total_clf_loss = 0\n",
    "    total_regularizaton_loss = 0\n",
    "    total_energy_loss = 0\n",
    "    total_spike_loss = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    spk3,memout=[],[]\n",
    "    # for each batch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # to device and reshape\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        B = target.size()[0]\n",
    "\n",
    "        for p in range(time_steps):\n",
    "            \n",
    "            if p == 0:\n",
    "                if rise_time:\n",
    "                    h = model.init_hidden_rise_time(data.size(0))\n",
    "                else:\n",
    "                    h = model.init_hidden(data.size(0))\n",
    "            elif p % omega == 0:\n",
    "                h = tuple(v.detach() for v in h)\n",
    "\n",
    "            if rise_time:\n",
    "                o, h = model.forward_rise_time(data, h)\n",
    "            else:\n",
    "                o, h = model.forward(data, h)\n",
    "            #print(\"\\n\\nbatch\",batch_idx)\n",
    "            #print(\"\\np\",p)\n",
    "            #print(\"\\nh1\",h[1],\"\\nh6\",h[6],\"\\nh11\",h[11])\n",
    "            #print(\"\\nmemout\",h[-1])\n",
    "            #spk3.append(h[11])\n",
    "            #memout.append(h[-1])\n",
    "\n",
    "            # wandb.log({\n",
    "            #         'rec layer adap threshold': h[5].detach().cpu().numpy(),\n",
    "            #         'rec layer mem potential': h[3].detach().cpu().numpy()\n",
    "            #     })\n",
    "\n",
    "            # get prediction\n",
    "            if p == (time_steps - 1):\n",
    "                pred = o.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "            if p % omega == 0 and p > 0:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # classification loss\n",
    "                #print(\"k updates\",k_updates,F.nll_loss(o, target),\"o\",o,o.shape,\"target\",target,target.shape)\n",
    "                clf_loss = (p + 1) / k_updates * F.nll_loss(o, target)\n",
    "                # clf_loss = snr*F.cross_entropy(output, target,reduction='none')\n",
    "                # clf_loss = torch.mean(clf_loss)\n",
    "\n",
    "                # regularizer loss\n",
    "                regularizer = get_regularizer_named_params(named_params, _lambda=1.0)\n",
    "\n",
    "                # mem potential loss take l1 norm / num of neurons /batch size\n",
    "                if len(model.hidden_dims) == 2:\n",
    "                    energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5])) / B / sum(model.hidden_dims)\n",
    "                elif len(model.hidden_dims) == 3:\n",
    "                    # energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2) + torch.sum(model.error3 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    energy = (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5]) + torch.sum(h[9])) / B / sum(model.hidden_dims)\n",
    "\n",
    "\n",
    "                # overall loss\n",
    "                #print(\"Loss\", clf_loss, regularizer, energy, spike_loss)\n",
    "                loss = clf_alpha * clf_loss + regularizer + energy_alpha * energy + spike_alpha * spike_loss\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "                optimizer.step()\n",
    "                post_optimizer_updates(named_params)\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total_clf_loss += clf_loss.item()\n",
    "                total_regularizaton_loss += regularizer  # .item()\n",
    "                total_energy_loss += energy.item()\n",
    "                total_spike_loss += spike_loss.item()\n",
    "\n",
    "\n",
    "                model.error1 = 0\n",
    "                model.error2 = 0\n",
    "                if len(model.hidden_dims) == 3:\n",
    "                    model.error3 = 0\n",
    "\n",
    "\n",
    "        if batch_idx > 0 and batch_idx % log_interval == (log_interval - 1):\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tenerg: {:.6f}\\tlr: {:.6f}\\ttrain acc:{:.4f}\\tLoss: {:.6f}\\\n",
    "                \\tClf: {:.6f}\\tReg: {:.6f}\\tFr_p: {:.6f}\\tFr_r: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), total_energy_loss / log_interval,\n",
    "                      lr, 100 * correct / (log_interval * B),\n",
    "                       train_loss / log_interval,\n",
    "                       total_clf_loss / log_interval, total_regularizaton_loss / log_interval,\n",
    "                       model.fr_layer2 / time_steps / log_interval,\n",
    "                       model.fr_layer1 / time_steps / log_interval))\n",
    "\n",
    "\n",
    "            train_loss = 0\n",
    "            total_clf_loss = 0\n",
    "            total_regularizaton_loss = 0\n",
    "            total_energy_loss = 0\n",
    "            total_spike_loss = 0\n",
    "            correct = 0\n",
    "            # model.network.fr = 0\n",
    "            model.fr_layer2 = 0\n",
    "            model.fr_layer1 = 0\n",
    "            if len(model.hidden_dims) == 3:\n",
    "                model.fr_layer3 = 0\n",
    "\n",
    "\n",
    "def train_fptt_decorr(epoch, batch_size, log_interval,\n",
    "               train_loader, model, named_params,\n",
    "               time_steps, k_updates, omega, optimizer,\n",
    "               clf_alpha, energy_alpha, spike_alpha, clip, lr, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4):\n",
    "    train_loss = 0\n",
    "    total_clf_loss = 0\n",
    "    total_regularizaton_loss = 0\n",
    "    total_energy_loss = 0\n",
    "    total_spike_loss = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "\n",
    "    # for each batch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # to device and reshape\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        B = target.size()[0]\n",
    "\n",
    "        for p in range(time_steps):\n",
    "\n",
    "            if p == 0:\n",
    "                h = model.init_hidden(data.size(0))\n",
    "            elif p % omega == 0:\n",
    "                h = tuple(v.detach() for v in h)\n",
    "\n",
    "            o, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4 = model.forward_decorrelation(data, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "            # wandb.log({\n",
    "            #         'rec layer adap threshold': h[5].detach().cpu().numpy(),\n",
    "            #         'rec layer mem potential': h[3].detach().cpu().numpy()\n",
    "            #     })\n",
    "\n",
    "            # get prediction\n",
    "            if p == (time_steps - 1):\n",
    "                pred = o.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "            if p % omega == 0 and p > 0:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # classification loss\n",
    "                clf_loss = (p + 1) / k_updates * F.nll_loss(o, target)\n",
    "                # clf_loss = snr*F.cross_entropy(output, target,reduction='none')\n",
    "                # clf_loss = torch.mean(clf_loss)\n",
    "\n",
    "                # regularizer loss\n",
    "                regularizer = get_regularizer_named_params(named_params, _lambda=1.0)\n",
    "\n",
    "                # mem potential loss take l1 norm / num of neurons /batch size\n",
    "                if len(model.hidden_dims) == 2:\n",
    "                    energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5])) / B / sum(model.hidden_dims)\n",
    "                elif len(model.hidden_dims) == 3:\n",
    "                    # energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2) + torch.sum(model.error3 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    energy = (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5]) + torch.sum(h[9])) / B / sum(model.hidden_dims)\n",
    "\n",
    "\n",
    "                # overall loss\n",
    "                loss = clf_alpha * clf_loss + regularizer + energy_alpha * energy + spike_alpha * spike_loss\n",
    "\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                if clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "                optimizer.step()\n",
    "                post_optimizer_updates(named_params)\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total_clf_loss += clf_loss.item()\n",
    "                total_regularizaton_loss += regularizer  # .item()\n",
    "                total_energy_loss += energy.item()\n",
    "                total_spike_loss += spike_loss.item()\n",
    "\n",
    "\n",
    "                model.error1 = 0\n",
    "                model.error2 = 0\n",
    "                if len(model.hidden_dims) == 3:\n",
    "                    model.error3 = 0\n",
    "\n",
    "\n",
    "        if batch_idx > 0 and batch_idx % log_interval == (log_interval - 1):\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tenerg: {:.6f}\\tlr: {:.6f}\\ttrain acc:{:.4f}\\tLoss: {:.6f}\\\n",
    "                \\tClf: {:.6f}\\tReg: {:.6f}\\tFr_p: {:.6f}\\tFr_r: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), total_energy_loss / log_interval,\n",
    "                      lr, 100 * correct / (log_interval * B),\n",
    "                       train_loss / log_interval,\n",
    "                       total_clf_loss / log_interval, total_regularizaton_loss / log_interval,\n",
    "                       model.fr_layer2 / time_steps / log_interval,\n",
    "                       model.fr_layer1 / time_steps / log_interval))\n",
    "\n",
    "\n",
    "            train_loss = 0\n",
    "            total_clf_loss = 0\n",
    "            total_regularizaton_loss = 0\n",
    "            total_energy_loss = 0\n",
    "            total_spike_loss = 0\n",
    "            correct = 0\n",
    "            # model.network.fr = 0\n",
    "            model.fr_layer2 = 0\n",
    "            model.fr_layer1 = 0\n",
    "            if len(model.hidden_dims) == 3:\n",
    "                model.fr_layer3 = 0\n",
    "\n",
    "    return decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCAgkJ3hkxPH"
   },
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WL8XFlKykz7K"
   },
   "outputs": [],
   "source": [
    "# test function\n",
    "def test(model, test_loader, time_steps):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_energy = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference(data, hidden, time_steps)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "            test_energy += (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / target.size()[0] / sum(model.hidden_dims)\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    test_energy /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset), test_energy\n",
    "\n",
    "# test function\n",
    "def test_with_added_noise(model, test_loader, time_steps, noise_mean, noise_std):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_energy = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data + torch.randn(data.size()) * noise_std + noise_mean\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference(data, hidden, time_steps)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "            test_energy += (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / target.size()[0] / sum(model.hidden_dims)\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    test_energy /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset), test_energy\n",
    "\n",
    "def test_rise_time(model, test_loader, time_steps):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_energy = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden_rise_time(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference_rise_time(data, hidden, time_steps)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "            test_energy += (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / target.size()[0] / sum(model.hidden_dims)\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    test_energy /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset), test_energy\n",
    "\n",
    "# test function\n",
    "def test_decorrelation(model, test_loader, time_steps, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference_decorrelation(data, hidden, time_steps, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_DORsdsg-TS"
   },
   "source": [
    "## Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oaqFPBCFg0vF"
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "adap_neuron = True  # whether use adaptive neuron or not\n",
    "clf_alpha = 1\n",
    "\n",
    "model_type = \"energy\"\n",
    "if model_type == \"control\":\n",
    "    energy_alpha = 0\n",
    "else:\n",
    "    energy_alpha = 0.05\n",
    "    \n",
    "spike_alpha = 0.  # energy loss on spikes\n",
    "num_readout = 10\n",
    "onetoone = True\n",
    "lr = 1e-3\n",
    "alg = 'fptt'\n",
    "dp = 0.4\n",
    "is_rec = False\n",
    "\n",
    "# training parameters\n",
    "T = 50\n",
    "K = 10  # k_updates is num updates per sequence\n",
    "omega = int(T / K)  # update frequency\n",
    "clip = 1.\n",
    "log_interval = 20\n",
    "epochs = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias set to 0\n",
      "SnnNetwork3Layer(\n",
      "  (dp): Dropout(p=0.4, inplace=False)\n",
      "  (layer1): SnnLayer(\n",
      "    (fc_weights): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (layer1to2): Linear(in_features=600, out_features=500, bias=True)\n",
      "  (layer2to1): Linear(in_features=500, out_features=600, bias=True)\n",
      "  (layer2): SnnLayer(\n",
      "    (fc_weights): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (output_layer): OutputLayer(\n",
      "    (fc): Linear(in_features=500, out_features=10, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (out2layer2): Linear(in_features=10, out_features=500, bias=True)\n",
      "  (decorr_layer_0): Decorrelation()\n",
      "  (decorr_layer_1): Decorrelation()\n",
      "  (decorr_layer_2): Decorrelation()\n",
      "  (decorr_layer_3): Decorrelation()\n",
      "  (decorr_layer_4): Decorrelation()\n",
      "  (layer3): SnnLayer(\n",
      "    (fc_weights): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (layer2to3): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (layer3to2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (out2layer3): Linear(in_features=10, out_features=500, bias=True)\n",
      "  (input_fc): Linear(in_features=784, out_features=600, bias=True)\n",
      ")\n",
      "total param count 2455520\n"
     ]
    }
   ],
   "source": [
    "# set input and t param\n",
    "IN_dim = 784\n",
    "hidden_dim = [600, 500, 500]\n",
    "n_classes = 10\n",
    "rise_time=False\n",
    "\n",
    "# define network\n",
    "model = SnnNetwork3Layer(IN_dim, hidden_dim, n_classes, is_adapt=adap_neuron,\n",
    "                         one_to_one=onetoone, dp_rate=dp, is_rec=is_rec, rise_time=rise_time)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "# define new loss and optimiser\n",
    "total_params = count_parameters(model)\n",
    "print('total param count %i' % total_params)\n",
    "\n",
    "# define optimiser\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "# reduce the learning after 20 epochs by a factor of 10\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA-seG48koNP"
   },
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2650515/2279865490.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  control_model = torch.load('/home/p318679/Documents/SNN_PC_Multicomp/results/base_control/{}_model.pth'.format(load_epoch_control))\n",
      "/tmp/ipykernel_2650515/2279865490.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  energy_model = torch.load('/home/p318679/Documents/SNN_PC_Multicomp/results/base_energy/{}_model.pth'.format(load_epoch_energy))\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint to load for 97% accuracy\n",
    "load_epoch_control = 7\n",
    "load_epoch_energy = 9 \n",
    "\n",
    "control_model = torch.load('results/base_control/{}_model.pth'.format(load_epoch_control))\n",
    "energy_model = torch.load('results/base_energy/{}_model.pth'.format(load_epoch_energy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 5 c-f with clamping with uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamped_generate_surprise(model, test_class, input, h_clamped, T, clamp_value=0.5, clamp_bool=False, batch=False, noise=None):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param input: input containing input, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if clamp_bool:\n",
    "                if not batch:\n",
    "                    h_clamped[-1][0] = -clamp_value\n",
    "                    h_clamped[-1][0, test_class] = clamp_value\n",
    "                else:\n",
    "                    h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                    h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                    h_clamped[-1][:] += noise\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = model.forward(input, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist, h_clamped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(hiddens_all_: list, idx: int, hidden_dim_: int, batch_size, T=20, num_samples=10000):\n",
    "    \"\"\"\n",
    "    get a particular internal state depending on index passed to hidden\n",
    "    :param hidden_dim_: the size of a state, eg. num of r or p neurons\n",
    "    :param T: total time steps\n",
    "    :param hiddens_all_: list containing hidden states of all batch and time steps during inference\n",
    "    :param idx: which index in h is taken out\n",
    "    :return: np array containing desired states\n",
    "    \"\"\"\n",
    "    all_states = []\n",
    "    for batch_idx in range(len(hiddens_all_)):  # iterate over batch\n",
    "        batch_ = []\n",
    "        for t in range(T):\n",
    "            seq_ = []\n",
    "            for b in range(batch_size):\n",
    "                seq_.append(hiddens_all_[batch_idx][t][idx][b].detach().cpu().numpy())\n",
    "            seq_ = np.stack(seq_)\n",
    "            batch_.append(seq_)\n",
    "        batch_ = np.stack(batch_)\n",
    "        all_states.append(batch_)\n",
    "\n",
    "    all_states = np.stack(all_states)\n",
    "\n",
    "    return all_states.transpose(0, 2, 1, 3).reshape(num_samples, T, hidden_dim_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model,element,keep_time,seed,clamp_value):\n",
    "    set_seeds(seed)\n",
    "\n",
    "    # clamped generation of internal representations \n",
    "    no_input = torch.zeros((1, IN_dim)).to(device)\n",
    "\n",
    "    clamp_T = T \n",
    "\n",
    "    # Expected clamp class \n",
    "    result_id = 0\n",
    "    if keep_time:\n",
    "        l1_clamp_expected = np.zeros((10000, int(T/2), hidden_dim[0]))\n",
    "        l2_clamp_expected = np.zeros((10000, int(T/2), hidden_dim[1]))\n",
    "        l3_clamp_expected = np.zeros((10000, int(T/2), hidden_dim[2]))\n",
    "    else:\n",
    "        l1_clamp_expected = np.zeros((10000, hidden_dim[0]))\n",
    "        l2_clamp_expected = np.zeros((10000, hidden_dim[1]))\n",
    "        l3_clamp_expected = np.zeros((10000, hidden_dim[2]))\n",
    "\n",
    "    test_loader2 = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "    for batch_id, (x,y) in enumerate(test_loader2):\n",
    "\n",
    "        for input_class in range(10):\n",
    "            n_images = (y==input_class).sum()\n",
    "            for image_idx in range(n_images):\n",
    "                image = x[y==input_class][image_idx][0].reshape(1,784).to(device)\n",
    "                clamp_class = input_class\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "\n",
    "                    hidden_i = model.init_hidden(1)\n",
    "            \n",
    "                    # no input for T/4 timesteps before stimulus onset\n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # clamped stimulus for T/2 timesteps\n",
    "                    _, h_hist, hidden_i = clamped_generate_surprise(model, clamp_class, image, hidden_i, int(clamp_T / 2), clamp_value=clamp_value, clamp_bool=True)\n",
    "                    # no input for T/4 timesteps after stimulus \n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    \n",
    "                    if element == 'apical':\n",
    "                        #l1_E = get_states([h_hist], 2, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist], 6, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist], 10, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'soma':\n",
    "                        #l1_E = get_states([h_hist], 0, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist], 4, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist], 8, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'spikes':\n",
    "                        l1_E = get_states([h_hist], 1, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist], 5, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l3_E = get_states([h_hist], 9, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "\n",
    "                    if keep_time:\n",
    "                        l2_clamp_expected[result_id] += np.squeeze(l2_E)\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_expected[result_id] += np.squeeze(l1_E)\n",
    "                            l3_clamp_expected[result_id] += np.squeeze(l3_E)\n",
    "                    else:\n",
    "                        l2_clamp_expected[result_id] += np.squeeze(l2_E.mean(axis=1))\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_expected[result_id] += np.squeeze(l1_E.mean(axis=1))\n",
    "                            l3_clamp_expected[result_id] += np.squeeze(l3_E.mean(axis=1))\n",
    "\n",
    "                    result_id += 1\n",
    "                    if result_id > 9999:\n",
    "                        break\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # Surprise clamp class \n",
    "    result_id = 0\n",
    "    set_seeds(seed)\n",
    "    if keep_time:\n",
    "        l1_clamp_surprise = np.zeros((10000, int(T/2), hidden_dim[0]))\n",
    "        l2_clamp_surprise = np.zeros((10000, int(T/2), hidden_dim[1]))\n",
    "        l3_clamp_surprise = np.zeros((10000, int(T/2), hidden_dim[2]))\n",
    "    else:\n",
    "        l1_clamp_surprise = np.zeros((10000, hidden_dim[0]))\n",
    "        l2_clamp_surprise = np.zeros((10000, hidden_dim[1]))\n",
    "        l3_clamp_surprise = np.zeros((10000, hidden_dim[2]))\n",
    "\n",
    "    for batch_id, (x,y) in enumerate(test_loader2):\n",
    "        for input_class in range(10):\n",
    "            n_images = (y==input_class).sum()\n",
    "            for image_idx in range(n_images):\n",
    "                image = x[y==input_class][image_idx][0].reshape(1,784).to(device)\n",
    "                surprise_class = np.random.choice(np.array(list(set(range(10))-set([input_class]))))\n",
    "                clamp_class = surprise_class\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "\n",
    "                    hidden_i = model.init_hidden(1)\n",
    "        \n",
    "                    # no input for T/4 timesteps before stimulus onset\n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # clamped stimulus for T/2 timesteps\n",
    "                    _, h_hist, hidden_i = clamped_generate_surprise(model, clamp_class, image, hidden_i, int(clamp_T / 2), clamp_value=clamp_value, clamp_bool=True)\n",
    "                    # no input for T/4 timesteps after stimulus \n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    \n",
    "                    #\n",
    "                    if element == 'apical':\n",
    "                        #l1_E = get_states([h_hist], 2, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist], 6, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist], 10, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'soma':\n",
    "                        #l1_E = get_states([h_hist], 0, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist], 4, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist], 8, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'spikes':\n",
    "                        l1_E = get_states([h_hist], 1, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist], 5, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l3_E = get_states([h_hist], 9, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "\n",
    "                    if keep_time:\n",
    "                        l2_clamp_surprise[result_id] += np.squeeze(l2_E)\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_surprise[result_id] += np.squeeze(l1_E)\n",
    "                            l3_clamp_surprise[result_id] += np.squeeze(l3_E)\n",
    "                    else:\n",
    "                        l2_clamp_surprise[result_id] += np.squeeze(l2_E.mean(axis=1))\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_surprise[result_id] += np.squeeze(l1_E.mean(axis=1))\n",
    "                            l3_clamp_surprise[result_id] += np.squeeze(l3_E.mean(axis=1))\n",
    "\n",
    "                    result_id += 1\n",
    "                    if result_id > 9999:\n",
    "                        break\n",
    "                        \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    if element == 'spikes':\n",
    "        return l1_clamp_surprise,l1_clamp_expected, l2_clamp_surprise,l2_clamp_expected, l3_clamp_surprise,l3_clamp_expected\n",
    "    else:\n",
    "        return l2_clamp_surprise, l2_clamp_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,fig_number,element):\n",
    "    fig,ax=plt.subplots(1,1)\n",
    "    #_,bins2,_ = ax.hist(l2_diff_control.flatten(),bins=10,weights=[100/len(l2_diff_control.flatten())]*len(l2_diff_control.flatten()),label='Control')\n",
    "    #ax.hist(l2_diff_energy.flatten(),bins=10,weights=[100/len(l2_diff_energy.flatten())]*len(l2_diff_energy.flatten()),alpha=0.5,label='Energy')\n",
    "    # use static bins\n",
    "    palette = sns.color_palette(\"colorblind\")\n",
    "    pastel_blue = palette[0]\n",
    "    pastel_orange = palette[1]\n",
    "    \n",
    "    _,bins2,_ = ax.hist(l2_diff_control.flatten(),bins=[-0.05,-0.04,-0.03,-0.02,-0.01,0,0.01,0.02,0.03,0.04,0.05],weights=[100/len(l2_diff_control.flatten())]*len(l2_diff_control.flatten()),alpha=0.5,color=pastel_blue,label='Control')\n",
    "    ax.hist(l2_diff_energy.flatten(),bins=[-0.05,-0.04,-0.03,-0.02,-0.01,0,0.01,0.02,0.03,0.04,0.05],weights=[100/len(l2_diff_energy.flatten())]*len(l2_diff_energy.flatten()),alpha=0.5,color=pastel_orange,label='Energy')\n",
    "    \n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "    plt.legend(fontsize=20,loc='upper right')   \n",
    "    plt.ylabel('Percentage',fontsize=20)\n",
    "    plt.xlabel('MSD',fontsize=15)\n",
    "    plt.title('L2 {}'.format(element),fontsize=20)\n",
    "    plt.xticks(fontsize=17)\n",
    "    plt.yticks(fontsize=17)\n",
    "    plt.savefig('{}_surprise_voltage_diff_{}_with_uncertainty.png'.format(fig_number,element),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set clamp value. If 1 (maximum value), one class will be clamped to 1 and the rest to -1. If 0.1, one class will be clamped to 0.1 and the rest to -0.1, leading to more uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clamp_value = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_time=True # value of each neuron is averaged over all timepoints\n",
    "element='apical'\n",
    "l2_diff_control_surprise,l2_diff_control_expected  = get_results(control_model,element,keep_time,seed,clamp_value)\n",
    "l2_diff_energy_surprise,l2_diff_energy_expected = get_results(energy_model,element,keep_time,seed,clamp_value)\n",
    "\n",
    "l2_diff_control = np.mean(l2_diff_control_expected-l2_diff_control_surprise,axis=1)\n",
    "l2_diff_energy = np.mean(l2_diff_energy_expected-l2_diff_energy_surprise,axis=1)\n",
    "\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_apical_L2.npy',l2_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_apical_L2.npy',l2_diff_energy)\n",
    "\n",
    "plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,'5c','apical tuft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_time=True\n",
    "element='soma'\n",
    "l2_diff_control_surprise,l2_diff_control_expected  = get_results(control_model,element,keep_time,seed,clamp_value)\n",
    "l2_diff_energy_surprise,l2_diff_energy_expected = get_results(energy_model,element,keep_time,seed,clamp_value)\n",
    "\n",
    "l2_diff_control = np.mean(l2_diff_control_expected-l2_diff_control_surprise,axis=1)\n",
    "l2_diff_energy = np.mean(l2_diff_energy_expected-l2_diff_energy_surprise,axis=1)\n",
    "\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_soma_L2_with_uncertainty.npy',l2_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_soma_L2_with_uncertainty.npy',l2_diff_energy)\n",
    "\n",
    "plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,'soma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_time=True\n",
    "element='spikes'\n",
    "l1_diff_control_surprise,l1_diff_control_expected, l2_diff_control_surprise,l2_diff_control_expected, l3_diff_control_surprise,l3_diff_control_expected = get_results(control_model,element,keep_time,seed,clamp_value)\n",
    "l1_diff_energy_surprise,l1_diff_energy_expected, l2_diff_energy_surprise,l2_diff_energy_expected, l3_diff_energy_surprise,l3_diff_energy_expected = get_results(energy_model,element,keep_time,seed,clamp_value)\n",
    "\n",
    "l1_diff_control = np.mean(l1_diff_control_expected-l1_diff_control_surprise,axis=1)\n",
    "l1_diff_energy = np.mean(l1_diff_energy_expected-l1_diff_energy_surprise,axis=1)\n",
    "l2_diff_control = np.mean(l2_diff_control_expected-l2_diff_control_surprise,axis=1)\n",
    "l2_diff_energy = np.mean(l2_diff_energy_expected-l2_diff_energy_surprise,axis=1)\n",
    "l3_diff_control = np.mean(l3_diff_control_expected-l3_diff_control_surprise,axis=1)\n",
    "l3_diff_energy = np.mean(l3_diff_energy_expected-l3_diff_energy_surprise,axis=1)\n",
    "\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_spikes_L1_with_uncertainty.npy',l1_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_spikes_L1_with_uncertainty.npy',l1_diff_energy)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_spikes_L2_with_uncertainty.npy',l2_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_spikes_L2_with_uncertainty.npy',l2_diff_energy)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_spikes_L3_with_uncertainty.npy',l3_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_spikes_L3_with_uncertainty.npy',l3_diff_energy)\n",
    "\n",
    "plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,\"$\\delta$$R$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_time=True\n",
    "element='spikes'\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "X_axis = np.arange(3)\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "pastel_blue = palette[0]\n",
    "pastel_orange = palette[1]\n",
    "\n",
    "ax.bar(X_axis-0.2,[np.abs(l1_diff_control).mean(), np.abs(l2_diff_control).mean(), np.abs(l3_diff_control).mean()],0.4,color=pastel_blue,label=\"Control\")\n",
    "ax.bar(X_axis+0.2,[np.abs(l1_diff_energy).mean(), np.abs(l2_diff_energy).mean(), np.abs(l3_diff_energy).mean()],0.4,color=pastel_orange,label=\"Energy\")\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "labels=[\"1\",\"2\",\"3\"]\n",
    "plt.xticks(X_axis, labels, fontsize=20) \n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"Layer\",fontsize=20) \n",
    "plt.ylabel(r\"$\\delta$$R$\",fontsize=20) \n",
    "plt.title(r\"$\\delta$$R$ match vs. mismatch\",fontsize=20) \n",
    "plt.legend(fontsize=20) \n",
    "plt.savefig('graphs_intermediate_results\\\\surprise_voltage_diff_{}_average_with_uncertainty.png'.format('spikes'),bbox_inches='tight')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SNN_PC_Multicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
