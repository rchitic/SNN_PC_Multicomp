{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMA-943Aev9e"
   },
   "source": [
    "# Spiking multicompartment PC network\n",
    "\n",
    "## Abstract\n",
    "Predictive coding is a promising theoretical framework for understanding the hierarchical sensory processing in the brain, yet how it is implemented with cortical spiking neurons is still unclear. While most existing works have taken a hand-wiring approach to creating microcircuits which match experimental results, recent work in applying the optimisation approach revealed that cortical connectivity might result from self-organisation given some fundamental computational principle, ie. energy efficiency. We thus investigated whether predictive coding properties in a multicompartment spiking neural network can result from energy optimisation. We found that only the model trained with an energy objective in addition to a task-relevant objective was able to reconstruct internal representations given top-down expectation signals alone. Neurons in the energy-optimised model also showed differential responses to expected vs unexpected stimuli, qualitatively similar to experimental evidence for predictive coding. These findings indicated that predictive-coding-like behaviour might be an emergent property of energy optimisation, providing a new perspective on how predictive coding could be achieved in the cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e5fUxmZcxfc",
    "outputId": "87a4b8e1-ab15-4a24-dc7e-20a6796837c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set seed\n",
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RlhsaGdOj55t"
   },
   "outputs": [],
   "source": [
    "## Utils\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, prefix, filename='_rec2_bias_checkpoint.pth.tar'):\n",
    "    print('saving at ', prefix + filename)\n",
    "    torch.save(state, prefix + filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(prefix + filename, prefix + '_rec2_bias_model_best.pth.tar')\n",
    "\n",
    "\n",
    "def model_result_dict_load(fn):\n",
    "    \"\"\"load tar file with saved model\n",
    "\n",
    "    Args:\n",
    "        fn (str): tar file name\n",
    "\n",
    "    Returns:\n",
    "        dict: dictornary containing saved results\n",
    "    \"\"\"\n",
    "    with open(fn, 'rb') as f:\n",
    "        dict = torch.load(f)\n",
    "    return dict\n",
    "\n",
    "def save_model(model_name,model):\n",
    "    torch.save(model,\"{}_model.pth\".format(model_name))\n",
    "    torch.save(model.state_dict(),\"{}_state_dict.pth\".format(model_name))\n",
    "\n",
    "def load_model(model_name):\n",
    "    model=torch.load(\".\\\\{}_model.pth\".format(model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p7KkVxPfe8q"
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNZglAYUfXQF",
    "outputId": "1e81f699-656e-425f-b289-71eeff15ab2a"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "traindata = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testdata = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "# data loading\n",
    "train_loader = torch.utils.data.DataLoader(traindata, batch_size=batch_size,\n",
    "                                           shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfP3cI8BfnoK"
   },
   "source": [
    "## Surrogate gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1KJqRTDNgaqj"
   },
   "outputs": [],
   "source": [
    "\n",
    "b_j0 = 0.1  # neural threshold baseline\n",
    "\n",
    "R_m = 3  # membrane resistance\n",
    "gamma = .5  # gradient scale\n",
    "lens = 0.5\n",
    "\n",
    "\n",
    "def gaussian(x, mu=0., sigma=.5):\n",
    "    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(math.pi)) / sigma\n",
    "\n",
    "\n",
    "class ActFun_adp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):  # input = membrane potential- threshold\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(0).float()  # is firing ???\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # approximate the gradients\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        # temp = abs(input) < lens\n",
    "        scale = 6.0\n",
    "        hight = .15\n",
    "        # temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(math.pi))/lens\n",
    "        temp = gaussian(input, mu=0., sigma=lens) * (1. + hight) \\\n",
    "               - gaussian(input, mu=lens, sigma=scale * lens) * hight \\\n",
    "               - gaussian(input, mu=-lens, sigma=scale * lens) * hight\n",
    "        # temp =  gaussian(input, mu=0., sigma=lens)\n",
    "        return grad_input * temp.float() * gamma\n",
    "        # return grad_input\n",
    "\n",
    "\n",
    "act_fun_adp = ActFun_adp.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gAwZBV_5gKUS"
   },
   "outputs": [],
   "source": [
    "# layers\n",
    "def shifted_sigmoid(currents):\n",
    "    return (1 / (1 + torch.exp(-currents)) - 0.5)/2\n",
    "\n",
    "\n",
    "class SnnLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dim: int,\n",
    "            is_rec: bool,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            tau_m_init=15.,\n",
    "            tau_adap_init=20,\n",
    "            tau_a_init=15.,\n",
    "            dt = 0.5,\n",
    "            bias = True\n",
    "    ):\n",
    "        super(SnnLayer, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.is_rec = is_rec\n",
    "        self.is_adapt = is_adapt\n",
    "        self.one_to_one = one_to_one\n",
    "        self.dt = dt\n",
    "\n",
    "        if is_rec:\n",
    "            self.rec_w = nn.Linear(hidden_dim, hidden_dim, bias=bias)\n",
    "            # init weights\n",
    "            if bias:\n",
    "                nn.init.constant_(self.rec_w.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.rec_w.weight)\n",
    "\n",
    "            p = torch.full(self.rec_w.weight.size(), fill_value=0.5).to(device)\n",
    "            self.weight_mask = torch.bernoulli(p)\n",
    "\n",
    "        else:\n",
    "            self.fc_weights = nn.Linear(in_dim, hidden_dim, bias=bias)\n",
    "            if bias:\n",
    "                nn.init.constant_(self.fc_weights.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.fc_weights.weight)\n",
    "\n",
    "        # define param for time constants\n",
    "        self.tau_adp = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_m = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_a = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        nn.init.normal_(self.tau_adp, tau_adap_init, .1)\n",
    "        nn.init.normal_(self.tau_m, tau_m_init, .1)\n",
    "        nn.init.normal_(self.tau_a, tau_a_init, .1)\n",
    "\n",
    "        # self.tau_adp = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_m = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_a = nn.Parameter(torch.Tensor(1))\n",
    "\n",
    "        # nn.init.constant_(self.tau_adp, tau_adap_init)\n",
    "        # nn.init.constant_(self.tau_m, tau_m_init)\n",
    "        # nn.init.constant_(self.tau_a, tau_a_init)\n",
    "\n",
    "        # nn.init.normal_(self.tau_adp, 200., 20.)\n",
    "        # nn.init.normal_(self.tau_m, 20., .5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def mem_update(self, ff, fb, soma, spike, a_curr, b, is_adapt, baseline_thre=b_j0, r_m=3):\n",
    "        \"\"\"\n",
    "        mem update for each layer of neurons\n",
    "        :param ff: feedforward signal\n",
    "        :param fb: feedback signal to apical tuft\n",
    "        :param soma: mem voltage potential at soma\n",
    "        :param spike: spiking at last time step\n",
    "        :param a_curr: apical tuft current at last t\n",
    "        :param current: input current at last t\n",
    "        :param b: adaptive threshold\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # alpha = self.sigmoid(self.tau_m)\n",
    "        # rho = self.sigmoid(self.tau_adp)\n",
    "        # eta = self.sigmoid(self.tau_a)\n",
    "        alpha = torch.exp(-self.dt/self.tau_m)\n",
    "        rho = torch.exp(-self.dt/self.tau_adp)\n",
    "        eta = torch.exp(-self.dt/self.tau_a)\n",
    "\n",
    "        if is_adapt:\n",
    "            beta = 1.8\n",
    "        else:\n",
    "            beta = 0.\n",
    "\n",
    "        b = rho * b + (1 - rho) * spike  # adaptive contribution\n",
    "        new_thre = baseline_thre + beta * b  # udpated threshold\n",
    "        \n",
    "        current_new = ff \n",
    "\n",
    "        a_new = eta * a_curr + fb  # fb into apical tuft\n",
    "\n",
    "        #print(\"mem update\",current_decay , current_curr , ff, eta , a_curr , fb)\n",
    "        \n",
    "        soma_new = alpha * soma + shifted_sigmoid(a_new) + current_new - new_thre * spike\n",
    "        # soma_new = alpha * soma + shifted_sigmoid(a_new) + rise * ff - new_thre * spike\n",
    "        # soma_new = alpha * soma + 1/2 * (a_new) + ffs - new_thre * spike\n",
    "\n",
    "        inputs_ = soma_new - new_thre\n",
    "\n",
    "        spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
    "        # mem = (1 - spike) * mem\n",
    "\n",
    "        return soma_new, spike, a_new, new_thre, b\n",
    "\n",
    "    def forward(self, ff, fb, soma_t, spk_t, a_curr_t, b_t):\n",
    "        \"\"\"\n",
    "        forward function of a single layer. given previous neuron states and current input, update neuron states\n",
    "\n",
    "        :param ff: ff signal (not counting rec)\n",
    "        :param fb: fb top down signal\n",
    "        :param soma_t: soma voltage\n",
    "        :param a_curr_t: apical tuft voltage\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if self.is_rec:\n",
    "            self.rec_w.weight.data = self.rec_w.weight.data * self.weight_mask\n",
    "            # self.rec_w.weight.data = (self.rec_w.weight.data < 0).float() * self.rec_w.weight.data\n",
    "            r_in = ff + self.rec_w(spk_t)\n",
    "        else:\n",
    "            if self.one_to_one:\n",
    "                r_in = ff\n",
    "            else:\n",
    "                r_in = self.fc_weights(ff)\n",
    "\n",
    "        soma_t1, spk_t1, a_curr_t1, _, b_t1 = self.mem_update(r_in, fb, soma_t, spk_t, a_curr_t, b_t, self.is_adapt)\n",
    "\n",
    "        return soma_t1, spk_t1, a_curr_t1, b_t1\n",
    "\n",
    "\n",
    "class SnnLayerRiseTime(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dim: int,\n",
    "            is_rec: bool,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            tau_m_init=15.,\n",
    "            tau_curr_decay_init=10.,\n",
    "            tau_adap_init=20,\n",
    "            tau_a_init=15.,\n",
    "            dt = 0.5,\n",
    "            bias = True\n",
    "    ):\n",
    "        super(SnnLayerRiseTime, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.is_rec = is_rec\n",
    "        self.is_adapt = is_adapt\n",
    "        self.one_to_one = one_to_one\n",
    "        self.dt = dt\n",
    "\n",
    "        if is_rec:\n",
    "            self.rec_w = nn.Linear(hidden_dim, hidden_dim, bias=bias)\n",
    "            # init weights\n",
    "            if bias:\n",
    "                nn.init.constant_(self.rec_w.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.rec_w.weight)\n",
    "\n",
    "            p = torch.full(self.rec_w.weight.size(), fill_value=0.5).to(device)\n",
    "            self.weight_mask = torch.bernoulli(p)\n",
    "\n",
    "        else:\n",
    "            self.fc_weights = nn.Linear(in_dim, hidden_dim, bias=bias)\n",
    "            if bias:\n",
    "                nn.init.constant_(self.fc_weights.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.fc_weights.weight)\n",
    "\n",
    "        # define param for time constants\n",
    "        self.tau_adp = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_m = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_curr_decay = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "        self.tau_a = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        nn.init.normal_(self.tau_adp, tau_adap_init, .1)\n",
    "        nn.init.normal_(self.tau_m, tau_m_init, .1)\n",
    "        nn.init.normal_(self.tau_curr_decay, tau_curr_decay_init, .1)\n",
    "        nn.init.normal_(self.tau_a, tau_a_init, .1)\n",
    "\n",
    "        # self.tau_adp = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_m = nn.Parameter(torch.Tensor(1))\n",
    "        # self.tau_a = nn.Parameter(torch.Tensor(1))\n",
    "\n",
    "        # nn.init.constant_(self.tau_adp, tau_adap_init)\n",
    "        # nn.init.constant_(self.tau_m, tau_m_init)\n",
    "        # nn.init.constant_(self.tau_a, tau_a_init)\n",
    "\n",
    "        # nn.init.normal_(self.tau_adp, 200., 20.)\n",
    "        # nn.init.normal_(self.tau_m, 20., .5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def mem_update(self, ff, fb, soma, spike, a_curr, current_curr, b, is_adapt, baseline_thre=b_j0, r_m=3):\n",
    "        \"\"\"\n",
    "        mem update for each layer of neurons\n",
    "        :param ff: feedforward signal\n",
    "        :param fb: feedback signal to apical tuft\n",
    "        :param soma: mem voltage potential at soma\n",
    "        :param spike: spiking at last time step\n",
    "        :param a_curr: apical tuft current at last t\n",
    "        :param current: input current at last t\n",
    "        :param b: adaptive threshold\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # alpha = self.sigmoid(self.tau_m)\n",
    "        # rho = self.sigmoid(self.tau_adp)\n",
    "        # eta = self.sigmoid(self.tau_a)\n",
    "        alpha = torch.exp(-self.dt/self.tau_m)\n",
    "        current_decay = torch.exp(-self.dt/self.tau_curr_decay)\n",
    "        rho = torch.exp(-self.dt/self.tau_adp)\n",
    "        eta = torch.exp(-self.dt/self.tau_a)\n",
    "\n",
    "        if is_adapt:\n",
    "            beta = 1.8\n",
    "        else:\n",
    "            beta = 0.\n",
    "                \n",
    "        b = rho * b + (1 - rho) * spike  # adaptive contribution\n",
    "        new_thre = baseline_thre + beta * b  # udpated threshold\n",
    "        \n",
    "        current_new = current_decay * current_curr + ff\n",
    "\n",
    "        a_new = eta * a_curr + fb  # fb into apical tuft\n",
    "\n",
    "        #print(\"mem update\",current_decay , current_curr , ff, eta , a_curr , fb)\n",
    "        \n",
    "        soma_new = alpha * soma + shifted_sigmoid(a_new) + current_new - new_thre * spike\n",
    "        # soma_new = alpha * soma + shifted_sigmoid(a_new) + rise * ff - new_thre * spike\n",
    "        # soma_new = alpha * soma + 1/2 * (a_new) + ffs - new_thre * spike\n",
    "\n",
    "        inputs_ = soma_new - new_thre\n",
    "\n",
    "        spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
    "        # mem = (1 - spike) * mem\n",
    "\n",
    "        return soma_new, spike, a_new, current_new, new_thre, b\n",
    "\n",
    "    def forward(self, ff, fb, soma_t, spk_t, a_curr_t, current_curr_t, b_t):\n",
    "        \"\"\"\n",
    "        forward function of a single layer. given previous neuron states and current input, update neuron states\n",
    "\n",
    "        :param ff: ff signal (not counting rec)\n",
    "        :param fb: fb top down signal\n",
    "        :param soma_t: soma voltage\n",
    "        :param a_curr_t: apical tuft voltage\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if self.is_rec:\n",
    "            self.rec_w.weight.data = self.rec_w.weight.data * self.weight_mask\n",
    "            # self.rec_w.weight.data = (self.rec_w.weight.data < 0).float() * self.rec_w.weight.data\n",
    "            r_in = ff + self.rec_w(spk_t)\n",
    "        else:\n",
    "            if self.one_to_one:\n",
    "                r_in = ff\n",
    "            else:\n",
    "                r_in = self.fc_weights(ff)\n",
    "\n",
    "        soma_t1, spk_t1, a_curr_t1, current_curr_t1, _, b_t1 = self.mem_update(r_in, fb, soma_t, spk_t, a_curr_t, current_curr_t, b_t, self.is_adapt)\n",
    "\n",
    "        return soma_t1, spk_t1, a_curr_t1, current_curr_t1, b_t1\n",
    "        \n",
    "class OutputLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            out_dim: int,\n",
    "            is_fc: bool,\n",
    "            tau_fixed=None,\n",
    "            bias = True,\n",
    "            dt=0.5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        output layer class\n",
    "        :param is_fc: whether integrator is fc to r_out in rec or not\n",
    "        \"\"\"\n",
    "        super(OutputLayer, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.is_fc = is_fc\n",
    "        self.dt = dt\n",
    "\n",
    "        if is_fc:\n",
    "            self.fc = nn.Linear(in_dim, out_dim, bias=bias)\n",
    "            if bias:\n",
    "                nn.init.constant_(self.fc.bias, 0)\n",
    "            nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "        # tau_m\n",
    "        if tau_fixed is None:\n",
    "            self.tau_m = nn.Parameter(torch.Tensor(out_dim))\n",
    "            nn.init.constant_(self.tau_m, 5)\n",
    "        else:\n",
    "            self.tau_m = nn.Parameter(torch.Tensor(out_dim), requires_grad=False)\n",
    "            nn.init.constant_(self.tau_m, tau_fixed)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x_t, mem_t):\n",
    "        \"\"\"\n",
    "        integrator neuron without spikes\n",
    "        \"\"\"\n",
    "        alpha = torch.exp(-self.dt/self.tau_m)\n",
    "        # alpha = self.sigmoid(self.tau_m)\n",
    "\n",
    "        if self.is_fc:\n",
    "            x_t = self.fc(x_t)\n",
    "        else:\n",
    "            x_t = x_t.view(-1, 10, int(self.in_dim / 10)).mean(dim=2)  # sum up population spike\n",
    "\n",
    "        # d_mem = -soma_t + x_t\n",
    "        mem = (mem_t + x_t) * alpha\n",
    "        # mem = alpha * soma_t + (1 - alpha) * x_t\n",
    "        return mem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hpf_RNkHfknR"
   },
   "outputs": [],
   "source": [
    "# 2 hidden layers\n",
    "class Decorrelation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decorrelation, self).__init__()\n",
    "        self.decorr_matrix_next = None\n",
    "    \n",
    "    def forward(self, input, decorr_matrix_prev_batch):\n",
    "        n=1e-3\n",
    "        diag = torch.diag_embed(torch.square(input)) # (batch_size,hidden_dim,hidden_dim)\n",
    "\n",
    "        input = input.reshape(input.shape[0],input.shape[1],1) # (batch_size,hidden_dim,1)\n",
    "        input = torch.matmul(decorr_matrix_prev_batch, input) # (batch_size,hidden_dim,1)\n",
    "\n",
    "        mult = torch.matmul(input, torch.transpose(input,1,2)) # (batch_size,hidden_dim,hidden_dim)\n",
    "        update = torch.mean(mult - diag, dim=0) # (hidden_dim,hidden_dim)\n",
    "        self.decorr_matrix_next = decorr_matrix_prev_batch - n * torch.matmul(update, decorr_matrix_prev_batch) # (hidden_dim,hidden_dim)\n",
    "\n",
    "        input = input.reshape(input.shape[0],input.shape[1]) # (batch_size,hidden_dim)\n",
    "        return input\n",
    "        \n",
    "class SnnNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dims: list,\n",
    "            out_dim: int,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            dp_rate: float,\n",
    "            is_rec: bool,\n",
    "            rise_time: bool,\n",
    "            bias = True\n",
    "    ):\n",
    "        super(SnnNetwork, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.out_dim = out_dim\n",
    "        self.is_adapt = is_adapt\n",
    "        self.one_to_one = one_to_one\n",
    "        self.is_rec = is_rec\n",
    "        self.rise_time = rise_time\n",
    "        self.dp = nn.Dropout(dp_rate)\n",
    "\n",
    "        if self.rise_time:\n",
    "            self.layer1 = SnnLayerRiseTime(hidden_dims[0], hidden_dims[0], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "        else:\n",
    "            self.layer1 = SnnLayer(hidden_dims[0], hidden_dims[0], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "\n",
    "        # r in to r out\n",
    "        self.layer1to2 = nn.Linear(hidden_dims[0], hidden_dims[1], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer1to2.weight)\n",
    "\n",
    "        # r out to r in\n",
    "        self.layer2to1 = nn.Linear(hidden_dims[1], hidden_dims[0], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer2to1.weight)\n",
    "\n",
    "        if self.rise_time:\n",
    "            self.layer2 = SnnLayerRiseTime(hidden_dims[1], hidden_dims[1], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "        else:\n",
    "            self.layer2 = SnnLayer(hidden_dims[1], hidden_dims[1], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "\n",
    "        self.output_layer = OutputLayer(hidden_dims[1], out_dim, is_fc=True, bias=bias)\n",
    "\n",
    "        self.out2layer2 = nn.Linear(out_dim, hidden_dims[1], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.out2layer2.weight)\n",
    "\n",
    "        if bias:\n",
    "            nn.init.constant_(self.layer1to2.bias, 0)\n",
    "            nn.init.constant_(self.layer2to1.bias, 0)\n",
    "            nn.init.constant_(self.out2layer2.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "        self.fr_layer2 = 0\n",
    "        self.fr_layer1 = 0\n",
    "\n",
    "        self.error1 = 0\n",
    "        self.error2 = 0\n",
    "\n",
    "    def forward(self, x_t, h):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t*0.5)\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "\n",
    "        soma_1, spk_1, a_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[5]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], b_t=h[3])\n",
    "\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.out2layer2(F.normalize(h[-1], dim=1)), soma_t=h[4],\n",
    "                                                   spk_t=h[5], a_curr_t=h[6], b_t=h[7])\n",
    "\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_2, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, b_2,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "\n",
    "        return log_softmax, h\n",
    "\n",
    "    def inference(self, x_t, h, T, bystep=None):\n",
    "        \"\"\"\n",
    "        only called during inference\n",
    "        :param x_t: input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param bystep: if true, then x_t is a sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "\n",
    "            if bystep is None:\n",
    "                log_softmax, h = self.forward(x_t, h)\n",
    "            else:\n",
    "                log_softmax, h = self.forward(x_t[t], h)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h)\n",
    "            \n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def inference_rise_time(self, x_t, h, T, bystep=None):\n",
    "        \"\"\"\n",
    "        only called during inference\n",
    "        :param x_t: input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param bystep: if true, then x_t is a sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "\n",
    "            if bystep is None:\n",
    "                log_softmax, h = self.forward_rise_time(x_t, h)\n",
    "            else:\n",
    "                log_softmax, h = self.forward_rise_time(x_t[t], h)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h)\n",
    "            \n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def clamped_generate(self, test_class, zeros, h_clamped, T, clamp_value=1, batch=False, noise=None):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param zeros: input containing zeros, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if not batch:\n",
    "                h_clamped[-1][0] = -clamp_value\n",
    "                h_clamped[-1][0, test_class] = clamp_value\n",
    "            else:\n",
    "                h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                    h_clamped[-1][:] += noise\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = self.forward(zeros, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def clamped_generate_rise_time(self, test_class, zeros, h_clamped, T, clamp_value=1, batch=False, noise=None):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param zeros: input containing zeros, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if not batch:\n",
    "                h_clamped[-1][0] = -clamp_value\n",
    "                h_clamped[-1][0, test_class] = clamp_value\n",
    "            else:\n",
    "                h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                    h_clamped[-1][:] += noise\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = self.forward_rise_time(zeros, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist\n",
    "        \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            # r\n",
    "            weight.new(bsz, self.hidden_dims[0]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # p\n",
    "            weight.new(bsz, self.hidden_dims[1]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "\n",
    "\n",
    "# 3 hidden layers\n",
    "\n",
    "class SnnNetwork3Layer(SnnNetwork):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dims: list,\n",
    "            out_dim: int,\n",
    "            is_adapt: bool,\n",
    "            one_to_one: bool,\n",
    "            dp_rate: float,\n",
    "            is_rec: bool,\n",
    "            rise_time: bool,\n",
    "            bias = True\n",
    "    ):\n",
    "        super().__init__(in_dim, hidden_dims, out_dim, is_adapt, one_to_one, dp_rate, is_rec, rise_time)\n",
    "\n",
    "        # decorrelation\n",
    "        self.decorr_layer_0 = Decorrelation()\n",
    "        self.decorr_layer_1 = Decorrelation()\n",
    "        self.decorr_layer_2 = Decorrelation()\n",
    "        self.decorr_layer_3 = Decorrelation()\n",
    "        self.decorr_layer_4 = Decorrelation()\n",
    "\n",
    "        if self.rise_time:\n",
    "            self.layer3 = SnnLayerRiseTime(hidden_dims[2], hidden_dims[2], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "        else:\n",
    "            self.layer3 = SnnLayer(hidden_dims[2], hidden_dims[2], is_rec=is_rec, is_adapt=is_adapt,\n",
    "                               one_to_one=one_to_one, bias=bias)\n",
    "            \n",
    "        self.layer2to3 = nn.Linear(hidden_dims[1], hidden_dims[2], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer2to3.weight)\n",
    "\n",
    "        # r out to r in\n",
    "        self.layer3to2 = nn.Linear(hidden_dims[2], hidden_dims[1], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.layer3to2.weight)\n",
    "\n",
    "        self.output_layer = OutputLayer(hidden_dims[2], out_dim, is_fc=True)\n",
    "\n",
    "        self.out2layer3 = nn.Linear(out_dim, hidden_dims[2], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.out2layer3.weight)\n",
    "\n",
    "        self.fr_layer3 = 0\n",
    "\n",
    "        self.error3 = 0\n",
    "\n",
    "        self.input_fc = nn.Linear(in_dim, hidden_dims[0], bias=bias)\n",
    "        nn.init.xavier_uniform_(self.input_fc.weight)\n",
    "\n",
    "        if bias:\n",
    "            nn.init.constant_(self.layer2to3.bias, 0)\n",
    "            nn.init.constant_(self.layer3to2.bias, 0)\n",
    "            nn.init.constant_(self.out2layer3.bias, 0)\n",
    "            nn.init.constant_(self.input_fc.bias, 0)\n",
    "            print('bias set to 0')\n",
    "\n",
    "    def forward_rise_time(self, x_t, h):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t)\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "        x_t = self.input_fc(x_t)\n",
    "\n",
    "        soma_1, spk_1, a_curr_1, current_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[6]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], current_curr_t=h[3], b_t=h[4])\n",
    "\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, current_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.layer3to2(h[11]), soma_t=h[5],\n",
    "                                                   spk_t=h[6], a_curr_t=h[7], current_curr_t=h[8], b_t=h[9])\n",
    "\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        soma_3, spk_3, a_curr_3, current_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=self.out2layer3(F.normalize(h[-1], dim=1)), soma_t=h[10],\n",
    "                                                   spk_t=h[11], a_curr_t=h[12], current_curr_t=h[13], b_t=h[14])\n",
    "        # soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=0, soma_t=h[8],\n",
    "        #                                            spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "\n",
    "        self.error3 = a_curr_3 - soma_3\n",
    "\n",
    "        self.fr_layer3 = self.fr_layer3 + spk_3.detach().cpu().numpy().mean()\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_3, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, current_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, current_curr_2, b_2,\n",
    "             soma_3, spk_3, a_curr_3, current_curr_3, b_3,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "\n",
    "        return log_softmax, h\n",
    "\n",
    "    def forward(self, x_t, h):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t)\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "        x_t = self.input_fc(x_t)\n",
    "\n",
    "        soma_1, spk_1, a_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[5]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], b_t=h[3])\n",
    "\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.layer3to2(h[9]), soma_t=h[4],\n",
    "                                                   spk_t=h[5], a_curr_t=h[6], b_t=h[7])\n",
    "\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=self.out2layer3(F.normalize(h[-1], dim=1)), soma_t=h[8],\n",
    "                                                   spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "        # soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=0, soma_t=h[8],\n",
    "        #                                            spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "\n",
    "        self.error3 = a_curr_3 - soma_3\n",
    "\n",
    "        self.fr_layer3 = self.fr_layer3 + spk_3.detach().cpu().numpy().mean()\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_3, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, b_2,\n",
    "             soma_3, spk_3, a_curr_3, b_3,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "\n",
    "        return log_softmax, h\n",
    "        \n",
    "    def forward_decorrelation(self, x_t, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4):\n",
    "        batch_dim, input_size = x_t.shape\n",
    "\n",
    "        x_t = x_t.reshape(batch_dim, input_size).float()\n",
    "        x_t = self.dp(x_t)\n",
    "\n",
    "        # poisson\n",
    "        # x_t = x_t.gt(0.7).float()\n",
    "\n",
    "        # decorrelate input\n",
    "        x_t = self.decorr_layer_0(x_t, decorr_matrix_0)\n",
    "        decorr_matrix_0 = self.decorr_layer_0.decorr_matrix_next.data.clone()\n",
    "        x_t = self.input_fc(x_t)\n",
    "\n",
    "        # decorrelate input to L1\n",
    "        x_t = self.decorr_layer_1(x_t, decorr_matrix_1)\n",
    "        decorr_matrix_1 = self.decorr_layer_1.decorr_matrix_next.data.clone()\n",
    "        \n",
    "        soma_1, spk_1, a_curr_1, b_1 = self.layer1(ff=x_t, fb=self.layer2to1(h[5]), soma_t=h[0], spk_t=h[1],\n",
    "                                                   a_curr_t=h[2], b_t=h[3])\n",
    "        self.error1 = a_curr_1 - soma_1\n",
    "\n",
    "        # decorrelate input to L2\n",
    "        spk_1 = self.decorr_layer_2(spk_1, decorr_matrix_2)\n",
    "        decorr_matrix_2 = self.decorr_layer_2.decorr_matrix_next.data.clone()\n",
    "\n",
    "        # use out mem signal as feedback\n",
    "        soma_2, spk_2, a_curr_2, b_2 = self.layer2(ff=self.layer1to2(spk_1), fb=self.layer3to2(h[9]), soma_t=h[4],\n",
    "                                                   spk_t=h[5], a_curr_t=h[6], b_t=h[7])\n",
    "        self.error2 = a_curr_2 - soma_2\n",
    "\n",
    "        # decorrelate input to L3\n",
    "        spk_2 = self.decorr_layer_3(spk_2, decorr_matrix_3)\n",
    "        decorr_matrix_3 = self.decorr_layer_3.decorr_matrix_next.data.clone()\n",
    "\n",
    "        soma_3, spk_3, a_curr_3, b_3 = self.layer3(ff=self.layer2to3(spk_2), fb=self.out2layer3(F.normalize(h[-1], dim=1)), soma_t=h[8],\n",
    "                                                   spk_t=h[9], a_curr_t=h[10], b_t=h[11])\n",
    "        self.error3 = a_curr_3 - soma_3\n",
    "\n",
    "        # decorrelate input to output layer\n",
    "        spk_3 = self.decorr_layer_4(spk_3, decorr_matrix_4)\n",
    "        decorr_matrix_4 = self.decorr_layer_4.decorr_matrix_next.data.clone()\n",
    "        \n",
    "        self.fr_layer3 = self.fr_layer3 + spk_3.detach().cpu().numpy().mean()\n",
    "        self.fr_layer2 = self.fr_layer2 + spk_2.detach().cpu().numpy().mean()\n",
    "        self.fr_layer1 = self.fr_layer1 + spk_1.detach().cpu().numpy().mean()\n",
    "\n",
    "        # read out from r_out neurons\n",
    "        mem_out = self.output_layer(spk_3, h[-1])\n",
    "\n",
    "        h = (soma_1, spk_1, a_curr_1, b_1,\n",
    "             soma_2, spk_2, a_curr_2, b_2,\n",
    "             soma_3, spk_3, a_curr_3, b_3,\n",
    "             mem_out)\n",
    "\n",
    "        log_softmax = F.log_softmax(mem_out, dim=1)\n",
    "        return log_softmax, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4\n",
    "\n",
    "    def inference_decorrelation(self, x_t, h, T, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4, bystep=None):\n",
    "        \"\"\"\n",
    "        only called during inference\n",
    "        :param x_t: input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param bystep: if true, then x_t is a sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "\n",
    "            if bystep is None:\n",
    "                log_softmax, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4 = self.forward_decorrelation(x_t, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "            else:\n",
    "                log_softmax, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4 = self.forward_decorrelation(x_t[t], h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h)\n",
    "            \n",
    "        return log_softmax_hist, h_hist\n",
    "\n",
    "    def init_hidden_rise_time(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        return (\n",
    "            # l1\n",
    "            weight.new(bsz, self.hidden_dims[0]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # l2\n",
    "            weight.new(bsz, self.hidden_dims[1]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # l3\n",
    "            weight.new(bsz, self.hidden_dims[2]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        return (\n",
    "            # l1\n",
    "            weight.new(bsz, self.hidden_dims[0]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # l2\n",
    "            weight.new(bsz, self.hidden_dims[1]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # l3\n",
    "            weight.new(bsz, self.hidden_dims[2]).uniform_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "        \n",
    "    def init_hidden_allzero(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            # l1\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[0]).fill_(b_j0),\n",
    "            # l2\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[1]).fill_(b_j0),\n",
    "            # l3\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).zero_(),\n",
    "            weight.new(bsz, self.hidden_dims[2]).fill_(b_j0),\n",
    "            # layer out\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "            # sum spike\n",
    "            weight.new(bsz, self.out_dim).zero_(),\n",
    "        )\n",
    "\n",
    "    def clamp_withnoise(self, test_class, zeros, h_clamped, T, noise, index, batch=False, clamp_value=0.5):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param zeros: input containing zeros, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :param noise: noise values\n",
    "        :param index: index in h where noise is added to\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if not batch:\n",
    "                h_clamped[-1][0] = -clamp_value\n",
    "                h_clamped[-1][0, test_class] = clamp_value\n",
    "            else:\n",
    "                h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                h_clamped[index][:, :] += noise * h_clamped[index][:, :]\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = self.forward(zeros, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8p3rNn-kPx7"
   },
   "source": [
    "## FTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VOFtn6gOkPfk"
   },
   "outputs": [],
   "source": [
    "alpha = .2\n",
    "beta = .5\n",
    "rho = 0.\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_stats_named_params(model):\n",
    "    named_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        sm, lm, dm = param.detach().clone(), 0.0 * param.detach().clone(), 0.0 * param.detach().clone()\n",
    "        named_params[name] = (param, sm, lm, dm)\n",
    "    return named_params\n",
    "\n",
    "\n",
    "def post_optimizer_updates(named_params):\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        lm.data.add_(-alpha * (param - sm))\n",
    "        sm.data.mul_((1.0 - beta))\n",
    "        sm.data.add_(beta * param - (beta / alpha) * lm)\n",
    "\n",
    "\n",
    "def get_regularizer_named_params(named_params, _lambda=1.0):\n",
    "    regularization = torch.zeros([], device=device)\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        regularization += (rho - 1.) * torch.sum(param * lm)\n",
    "        r_p = _lambda * 0.5 * alpha * torch.sum(torch.square(param - sm))\n",
    "        regularization += r_p\n",
    "        # print(name,r_p)\n",
    "    return regularization\n",
    "\n",
    "\n",
    "def reset_named_params(named_params):\n",
    "    for name in named_params:\n",
    "        param, sm, lm, dm = named_params[name]\n",
    "        param.data.copy_(sm.data)\n",
    "\n",
    "\n",
    "def train_fptt(epoch, batch_size, log_interval,\n",
    "               train_loader, model, named_params,\n",
    "               time_steps, k_updates, omega, optimizer,\n",
    "               clf_alpha, energy_alpha, spike_alpha, clip, lr, rise_time):\n",
    "    train_loss = 0\n",
    "    total_clf_loss = 0\n",
    "    total_regularizaton_loss = 0\n",
    "    total_energy_loss = 0\n",
    "    total_spike_loss = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    spk3,memout=[],[]\n",
    "    # for each batch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # to device and reshape\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        B = target.size()[0]\n",
    "\n",
    "        for p in range(time_steps):\n",
    "            \n",
    "            if p == 0:\n",
    "                if rise_time:\n",
    "                    h = model.init_hidden_rise_time(data.size(0))\n",
    "                else:\n",
    "                    h = model.init_hidden(data.size(0))\n",
    "            elif p % omega == 0:\n",
    "                h = tuple(v.detach() for v in h)\n",
    "\n",
    "            if rise_time:\n",
    "                o, h = model.forward_rise_time(data, h)\n",
    "            else:\n",
    "                o, h = model.forward(data, h)\n",
    "            #print(\"\\n\\nbatch\",batch_idx)\n",
    "            #print(\"\\np\",p)\n",
    "            #print(\"\\nh1\",h[1],\"\\nh6\",h[6],\"\\nh11\",h[11])\n",
    "            #print(\"\\nmemout\",h[-1])\n",
    "            #spk3.append(h[11])\n",
    "            #memout.append(h[-1])\n",
    "\n",
    "            # wandb.log({\n",
    "            #         'rec layer adap threshold': h[5].detach().cpu().numpy(),\n",
    "            #         'rec layer mem potential': h[3].detach().cpu().numpy()\n",
    "            #     })\n",
    "\n",
    "            # get prediction\n",
    "            if p == (time_steps - 1):\n",
    "                pred = o.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "            if p % omega == 0 and p > 0:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # classification loss\n",
    "                #print(\"k updates\",k_updates,F.nll_loss(o, target),\"o\",o,o.shape,\"target\",target,target.shape)\n",
    "                clf_loss = (p + 1) / k_updates * F.nll_loss(o, target)\n",
    "                # clf_loss = snr*F.cross_entropy(output, target,reduction='none')\n",
    "                # clf_loss = torch.mean(clf_loss)\n",
    "\n",
    "                # regularizer loss\n",
    "                regularizer = get_regularizer_named_params(named_params, _lambda=1.0)\n",
    "\n",
    "                # mem potential loss take l1 norm / num of neurons /batch size\n",
    "                if len(model.hidden_dims) == 2:\n",
    "                    energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5])) / B / sum(model.hidden_dims)\n",
    "                elif len(model.hidden_dims) == 3:\n",
    "                    # energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2) + torch.sum(model.error3 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    energy = (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5]) + torch.sum(h[9])) / B / sum(model.hidden_dims)\n",
    "\n",
    "\n",
    "                # overall loss\n",
    "                #print(\"Loss\", clf_loss, regularizer, energy, spike_loss)\n",
    "                loss = clf_alpha * clf_loss + regularizer + energy_alpha * energy + spike_alpha * spike_loss\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "                optimizer.step()\n",
    "                post_optimizer_updates(named_params)\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total_clf_loss += clf_loss.item()\n",
    "                total_regularizaton_loss += regularizer  # .item()\n",
    "                total_energy_loss += energy.item()\n",
    "                total_spike_loss += spike_loss.item()\n",
    "\n",
    "\n",
    "                model.error1 = 0\n",
    "                model.error2 = 0\n",
    "                if len(model.hidden_dims) == 3:\n",
    "                    model.error3 = 0\n",
    "\n",
    "\n",
    "        if batch_idx > 0 and batch_idx % log_interval == (log_interval - 1):\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tenerg: {:.6f}\\tlr: {:.6f}\\ttrain acc:{:.4f}\\tLoss: {:.6f}\\\n",
    "                \\tClf: {:.6f}\\tReg: {:.6f}\\tFr_p: {:.6f}\\tFr_r: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), total_energy_loss / log_interval,\n",
    "                      lr, 100 * correct / (log_interval * B),\n",
    "                       train_loss / log_interval,\n",
    "                       total_clf_loss / log_interval, total_regularizaton_loss / log_interval,\n",
    "                       model.fr_layer2 / time_steps / log_interval,\n",
    "                       model.fr_layer1 / time_steps / log_interval))\n",
    "\n",
    "\n",
    "            train_loss = 0\n",
    "            total_clf_loss = 0\n",
    "            total_regularizaton_loss = 0\n",
    "            total_energy_loss = 0\n",
    "            total_spike_loss = 0\n",
    "            correct = 0\n",
    "            # model.network.fr = 0\n",
    "            model.fr_layer2 = 0\n",
    "            model.fr_layer1 = 0\n",
    "            if len(model.hidden_dims) == 3:\n",
    "                model.fr_layer3 = 0\n",
    "\n",
    "\n",
    "def train_fptt_decorr(epoch, batch_size, log_interval,\n",
    "               train_loader, model, named_params,\n",
    "               time_steps, k_updates, omega, optimizer,\n",
    "               clf_alpha, energy_alpha, spike_alpha, clip, lr, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4):\n",
    "    train_loss = 0\n",
    "    total_clf_loss = 0\n",
    "    total_regularizaton_loss = 0\n",
    "    total_energy_loss = 0\n",
    "    total_spike_loss = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "\n",
    "    # for each batch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # to device and reshape\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        B = target.size()[0]\n",
    "\n",
    "        for p in range(time_steps):\n",
    "\n",
    "            if p == 0:\n",
    "                h = model.init_hidden(data.size(0))\n",
    "            elif p % omega == 0:\n",
    "                h = tuple(v.detach() for v in h)\n",
    "\n",
    "            o, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4 = model.forward_decorrelation(data, h, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "            # wandb.log({\n",
    "            #         'rec layer adap threshold': h[5].detach().cpu().numpy(),\n",
    "            #         'rec layer mem potential': h[3].detach().cpu().numpy()\n",
    "            #     })\n",
    "\n",
    "            # get prediction\n",
    "            if p == (time_steps - 1):\n",
    "                pred = o.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "            if p % omega == 0 and p > 0:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # classification loss\n",
    "                clf_loss = (p + 1) / k_updates * F.nll_loss(o, target)\n",
    "                # clf_loss = snr*F.cross_entropy(output, target,reduction='none')\n",
    "                # clf_loss = torch.mean(clf_loss)\n",
    "\n",
    "                # regularizer loss\n",
    "                regularizer = get_regularizer_named_params(named_params, _lambda=1.0)\n",
    "\n",
    "                # mem potential loss take l1 norm / num of neurons /batch size\n",
    "                if len(model.hidden_dims) == 2:\n",
    "                    energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5])) / B / sum(model.hidden_dims)\n",
    "                elif len(model.hidden_dims) == 3:\n",
    "                    # energy = (torch.sum(model.error1 ** 2) + torch.sum(model.error2 ** 2) + torch.sum(model.error3 ** 2)) / B / sum(model.hidden_dims)\n",
    "                    energy = (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / B / sum(model.hidden_dims)\n",
    "                    spike_loss = (torch.sum(h[1]) + torch.sum(h[5]) + torch.sum(h[9])) / B / sum(model.hidden_dims)\n",
    "\n",
    "\n",
    "                # overall loss\n",
    "                loss = clf_alpha * clf_loss + regularizer + energy_alpha * energy + spike_alpha * spike_loss\n",
    "\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                if clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "                optimizer.step()\n",
    "                post_optimizer_updates(named_params)\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total_clf_loss += clf_loss.item()\n",
    "                total_regularizaton_loss += regularizer  # .item()\n",
    "                total_energy_loss += energy.item()\n",
    "                total_spike_loss += spike_loss.item()\n",
    "\n",
    "\n",
    "                model.error1 = 0\n",
    "                model.error2 = 0\n",
    "                if len(model.hidden_dims) == 3:\n",
    "                    model.error3 = 0\n",
    "\n",
    "\n",
    "        if batch_idx > 0 and batch_idx % log_interval == (log_interval - 1):\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tenerg: {:.6f}\\tlr: {:.6f}\\ttrain acc:{:.4f}\\tLoss: {:.6f}\\\n",
    "                \\tClf: {:.6f}\\tReg: {:.6f}\\tFr_p: {:.6f}\\tFr_r: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), total_energy_loss / log_interval,\n",
    "                      lr, 100 * correct / (log_interval * B),\n",
    "                       train_loss / log_interval,\n",
    "                       total_clf_loss / log_interval, total_regularizaton_loss / log_interval,\n",
    "                       model.fr_layer2 / time_steps / log_interval,\n",
    "                       model.fr_layer1 / time_steps / log_interval))\n",
    "\n",
    "\n",
    "            train_loss = 0\n",
    "            total_clf_loss = 0\n",
    "            total_regularizaton_loss = 0\n",
    "            total_energy_loss = 0\n",
    "            total_spike_loss = 0\n",
    "            correct = 0\n",
    "            # model.network.fr = 0\n",
    "            model.fr_layer2 = 0\n",
    "            model.fr_layer1 = 0\n",
    "            if len(model.hidden_dims) == 3:\n",
    "                model.fr_layer3 = 0\n",
    "\n",
    "    return decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCAgkJ3hkxPH"
   },
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WL8XFlKykz7K"
   },
   "outputs": [],
   "source": [
    "# test function\n",
    "def test(model, test_loader, time_steps):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_energy = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference(data, hidden, time_steps)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "            test_energy += (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / target.size()[0] / sum(model.hidden_dims)\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    test_energy /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset), test_energy\n",
    "\n",
    "# test function\n",
    "def test_with_added_noise(model, test_loader, time_steps, noise_mean, noise_std):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_energy = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data + torch.randn(data.size()) * noise_std + noise_mean\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference(data, hidden, time_steps)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "            test_energy += (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / target.size()[0] / sum(model.hidden_dims)\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    test_energy /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset), test_energy\n",
    "\n",
    "def test_rise_time(model, test_loader, time_steps):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_energy = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden_rise_time(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference_rise_time(data, hidden, time_steps)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "            test_energy += (torch.sum(torch.abs(model.error1)) + torch.sum(torch.abs(model.error2)) + torch.sum(torch.abs(model.error3))) / target.size()[0] / sum(model.hidden_dims)\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    test_energy /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset), test_energy\n",
    "\n",
    "# test function\n",
    "def test_decorrelation(model, test_loader, time_steps, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # for data, target in test_loader:\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, model.in_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            hidden = model.init_hidden(data.size(0))\n",
    "            \n",
    "            log_softmax_outputs, hidden = model.inference_decorrelation(data, hidden, time_steps, decorr_matrix_0, decorr_matrix_1, decorr_matrix_2, decorr_matrix_3, decorr_matrix_4)\n",
    "\n",
    "            test_loss += F.nll_loss(log_softmax_outputs[-1], target, reduction='sum').data.item()\n",
    "\n",
    "            pred = log_softmax_outputs[-1].data.max(1, keepdim=True)[1]\n",
    "\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # wandb.log({'spike sequence': plot_spiking_sequence(hidden, target)})\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acc))\n",
    "\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_DORsdsg-TS"
   },
   "source": [
    "## Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oaqFPBCFg0vF"
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "adap_neuron = True  # whether use adaptive neuron or not\n",
    "clf_alpha = 1\n",
    "\n",
    "model_type = \"energy\"\n",
    "if model_type == \"control\":\n",
    "    energy_alpha = 0\n",
    "else:\n",
    "    energy_alpha = 0.05\n",
    "    \n",
    "spike_alpha = 0.  # energy loss on spikes\n",
    "num_readout = 10\n",
    "onetoone = True\n",
    "lr = 1e-3\n",
    "alg = 'fptt'\n",
    "dp = 0.4\n",
    "is_rec = False\n",
    "\n",
    "# training parameters\n",
    "T = 50\n",
    "K = 10  # k_updates is num updates per sequence\n",
    "omega = int(T / K)  # update frequency\n",
    "clip = 1.\n",
    "log_interval = 20\n",
    "epochs = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias set to 0\n",
      "SnnNetwork3Layer(\n",
      "  (dp): Dropout(p=0.4, inplace=False)\n",
      "  (layer1): SnnLayer(\n",
      "    (fc_weights): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (layer1to2): Linear(in_features=600, out_features=500, bias=True)\n",
      "  (layer2to1): Linear(in_features=500, out_features=600, bias=True)\n",
      "  (layer2): SnnLayer(\n",
      "    (fc_weights): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (output_layer): OutputLayer(\n",
      "    (fc): Linear(in_features=500, out_features=10, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (out2layer2): Linear(in_features=10, out_features=500, bias=True)\n",
      "  (decorr_layer_0): Decorrelation()\n",
      "  (decorr_layer_1): Decorrelation()\n",
      "  (decorr_layer_2): Decorrelation()\n",
      "  (decorr_layer_3): Decorrelation()\n",
      "  (decorr_layer_4): Decorrelation()\n",
      "  (layer3): SnnLayer(\n",
      "    (fc_weights): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (layer2to3): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (layer3to2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (out2layer3): Linear(in_features=10, out_features=500, bias=True)\n",
      "  (input_fc): Linear(in_features=784, out_features=600, bias=True)\n",
      ")\n",
      "total param count 2455520\n"
     ]
    }
   ],
   "source": [
    "# set input and t param\n",
    "IN_dim = 784\n",
    "hidden_dim = [600, 500, 500]\n",
    "n_classes = 10\n",
    "rise_time=False\n",
    "\n",
    "# define network\n",
    "model = SnnNetwork3Layer(IN_dim, hidden_dim, n_classes, is_adapt=adap_neuron,\n",
    "                         one_to_one=onetoone, dp_rate=dp, is_rec=is_rec, rise_time=rise_time)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "# define new loss and optimiser\n",
    "total_params = count_parameters(model)\n",
    "print('total param count %i' % total_params)\n",
    "\n",
    "# define optimiser\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "# reduce the learning after 20 epochs by a factor of 10\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA-seG48koNP"
   },
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2877911/2279865490.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  control_model = torch.load('/home/p318679/Documents/SNN_PC_Multicomp/results/base_control/{}_model.pth'.format(load_epoch_control))\n",
      "/tmp/ipykernel_2877911/2279865490.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  energy_model = torch.load('/home/p318679/Documents/SNN_PC_Multicomp/results/base_energy/{}_model.pth'.format(load_epoch_energy))\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint to load for 97% accuracy\n",
    "load_epoch_control = 7\n",
    "load_epoch_energy = 9 \n",
    "\n",
    "control_model = torch.load('results/base_control/{}_model.pth'.format(load_epoch_control))\n",
    "energy_model = torch.load('results/base_energy/{}_model.pth'.format(load_epoch_energy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 5 c-f with match / mismatch between consecutive inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamped_generate_surprise(model, test_class, input, h_clamped, T, clamp_value=1, clamp_bool=False, batch=False, noise=None):\n",
    "        \"\"\"\n",
    "        generate representations with mem of read out clamped\n",
    "        :param test_class: which class is clamped\n",
    "        :param input: input containing input, absence of input\n",
    "        :param h: hidden states\n",
    "        :param T: sequence length\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        log_softmax_hist = []\n",
    "        h_hist = []\n",
    "\n",
    "        for t in range(T):\n",
    "            if clamp_bool:\n",
    "                if not batch:\n",
    "                    h_clamped[-1][0] = -clamp_value\n",
    "                    h_clamped[-1][0, test_class] = clamp_value\n",
    "                else:\n",
    "                    h_clamped[-1][:, :] = torch.full(h_clamped[-1].size(), -clamp_value).to(device)\n",
    "                    h_clamped[-1][:, test_class] = clamp_value\n",
    "\n",
    "            if noise is not None:\n",
    "                    h_clamped[-1][:] += noise\n",
    "\n",
    "            # if t==0:\n",
    "            #     print(h_clamped[-1])\n",
    "\n",
    "            log_softmax, h_clamped = model.forward(input, h_clamped)\n",
    "\n",
    "            log_softmax_hist.append(log_softmax)\n",
    "            h_hist.append(h_clamped)\n",
    "\n",
    "        return log_softmax_hist, h_hist, h_clamped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(hiddens_all_: list, idx: int, hidden_dim_: int, batch_size, T=20, num_samples=10000):\n",
    "    \"\"\"\n",
    "    get a particular internal state depending on index passed to hidden\n",
    "    :param hidden_dim_: the size of a state, eg. num of r or p neurons\n",
    "    :param T: total time steps\n",
    "    :param hiddens_all_: list containing hidden states of all batch and time steps during inference\n",
    "    :param idx: which index in h is taken out\n",
    "    :return: np array containing desired states\n",
    "    \"\"\"\n",
    "    all_states = []\n",
    "    for batch_idx in range(len(hiddens_all_)):  # iterate over batch\n",
    "        batch_ = []\n",
    "        for t in range(T):\n",
    "            seq_ = []\n",
    "            for b in range(batch_size):\n",
    "                seq_.append(hiddens_all_[batch_idx][t][idx][b].detach().cpu().numpy())\n",
    "            seq_ = np.stack(seq_)\n",
    "            batch_.append(seq_)\n",
    "        batch_ = np.stack(batch_)\n",
    "        all_states.append(batch_)\n",
    "\n",
    "    all_states = np.stack(all_states)\n",
    "\n",
    "    return all_states.transpose(0, 2, 1, 3).reshape(num_samples, T, hidden_dim_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model,element,keep_time,seed,clamp_value):\n",
    "    set_seeds(seed)\n",
    "\n",
    "    # clamped generation of internal representations \n",
    "    no_input = torch.zeros((1, IN_dim)).to(device)\n",
    "\n",
    "    clamp_T = T \n",
    "\n",
    "    # Match between consecutive inputs (they belong to the same class)\n",
    "    result_id = 0\n",
    "    if keep_time:\n",
    "        l1_clamp_expected = np.zeros((10000, int(T/2), hidden_dim[0]))\n",
    "        l2_clamp_expected = np.zeros((10000, int(T/2), hidden_dim[1]))\n",
    "        l3_clamp_expected = np.zeros((10000, int(T/2), hidden_dim[2]))\n",
    "    else:\n",
    "        l1_clamp_expected = np.zeros((10000, hidden_dim[0]))\n",
    "        l2_clamp_expected = np.zeros((10000, hidden_dim[1]))\n",
    "        l3_clamp_expected = np.zeros((10000, hidden_dim[2]))\n",
    "\n",
    "    test_loader2 = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "    for batch_id, (x,y) in enumerate(test_loader2):\n",
    "\n",
    "        for input_class in range(10):\n",
    "            n_images = (y==input_class).sum()\n",
    "            for image_idx in range(0,10,2):\n",
    "                image1 = x[y==input_class][image_idx][0].reshape(1,784).to(device)\n",
    "                image2 = x[y==input_class][image_idx+1][0].reshape(1,784).to(device)\n",
    "                clamp_class = input_class\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "\n",
    "                    hidden_i = model.init_hidden(1)\n",
    "                    # no input for T/4 timesteps before stimulus onset\n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # clamped stimulus for T/2 timesteps\n",
    "                    _, h_hist1, hidden_i = clamped_generate_surprise(model, clamp_class, image1, hidden_i, int(clamp_T / 2), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # no input for T/4 timesteps after stimulus \n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    \n",
    "                    # no input for T/4 timesteps before stimulus onset\n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # clamped stimulus for T/2 timesteps\n",
    "                    _, h_hist2, hidden_i = clamped_generate_surprise(model, clamp_class, image2, hidden_i, int(clamp_T / 2), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # no input for T/4 timesteps after stimulus \n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "\n",
    "                    if element == 'apical':\n",
    "                        #l1_E = get_states([h_hist2], 2, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist2], 6, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist2], 10, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'soma':\n",
    "                        #l1_E = get_states([h_hist2], 0, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist2], 4, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist2], 8, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'spikes':\n",
    "                        l1_E = get_states([h_hist2], 1, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist2], 5, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l3_E = get_states([h_hist2], 9, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "\n",
    "                    if keep_time:\n",
    "                        l2_clamp_expected[result_id] += np.squeeze(l2_E)\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_expected[result_id] += np.squeeze(l1_E)\n",
    "                            l3_clamp_expected[result_id] += np.squeeze(l3_E)\n",
    "                    else:\n",
    "                        l2_clamp_expected[result_id] += np.squeeze(l2_E.mean(axis=1))\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_expected[result_id] += np.squeeze(l1_E.mean(axis=1))\n",
    "                            l3_clamp_expected[result_id] += np.squeeze(l3_E.mean(axis=1))\n",
    "\n",
    "                    result_id += 1\n",
    "                    if result_id > 9999:\n",
    "                        break\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # Mismatch between consecutive inputs (they belong to different classes)\n",
    "    result_id = 0\n",
    "    set_seeds(seed)\n",
    "    if keep_time:\n",
    "        l1_clamp_surprise = np.zeros((10000, int(T/2), hidden_dim[0]))\n",
    "        l2_clamp_surprise = np.zeros((10000, int(T/2), hidden_dim[1]))\n",
    "        l3_clamp_surprise = np.zeros((10000, int(T/2), hidden_dim[2]))\n",
    "    else:\n",
    "        l1_clamp_surprise = np.zeros((10000, hidden_dim[0]))\n",
    "        l2_clamp_surprise = np.zeros((10000, hidden_dim[1]))\n",
    "        l3_clamp_surprise = np.zeros((10000, hidden_dim[2]))\n",
    "\n",
    "    for batch_id, (x,y) in enumerate(test_loader2):\n",
    "        for input_class in range(10):\n",
    "            n_images = (y==input_class).sum()\n",
    "            for image_idx in range(0,10,2):\n",
    "                image1 = x[y==input_class][image_idx][0].reshape(1,784).to(device)\n",
    "                surprise_class = np.random.choice(np.array(list(set(range(10))-set([input_class]))))\n",
    "                image2 = x[y==surprise_class][image_idx][0].reshape(1,784).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "\n",
    "                    clamp_class = input_class\n",
    "                    hidden_i = model.init_hidden(1)\n",
    "                    # no input for T/4 timesteps before stimulus onset\n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # clamped stimulus for T/2 timesteps\n",
    "                    _, h_hist1, hidden_i = clamped_generate_surprise(model, clamp_class, image1, hidden_i, int(clamp_T / 2), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # no input for T/4 timesteps after stimulus \n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    \n",
    "                    clamp_class = surprise_class\n",
    "                    # no input for T/4 timesteps before stimulus onset\n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # clamped stimulus for T/2 timesteps\n",
    "                    _, h_hist2, hidden_i = clamped_generate_surprise(model, clamp_class, image2, hidden_i, int(clamp_T / 2), clamp_value=clamp_value, clamp_bool=False)\n",
    "                    # no input for T/4 timesteps after stimulus \n",
    "                    _, _, hidden_i = clamped_generate_surprise(model, clamp_class, no_input, hidden_i, int(clamp_T / 4), clamp_value=clamp_value, clamp_bool=False)\n",
    "\n",
    "                    #\n",
    "                    if element == 'apical':\n",
    "                        #l1_E = get_states([h_hist2], 2, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist2], 6, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist2], 10, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'soma':\n",
    "                        #l1_E = get_states([h_hist2], 0, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist2], 4, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        #l3_E = get_states([h_hist2], 8, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "                    elif element == 'spikes':\n",
    "                        l1_E = get_states([h_hist2], 1, hidden_dim[0], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l2_E = get_states([h_hist2], 5, hidden_dim[1], 1, int(clamp_T/2), num_samples=1)\n",
    "                        l3_E = get_states([h_hist2], 9, hidden_dim[2], 1, int(clamp_T/2), num_samples=1)\n",
    "\n",
    "                    if keep_time:\n",
    "                        l2_clamp_surprise[result_id] += np.squeeze(l2_E)\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_surprise[result_id] += np.squeeze(l1_E)\n",
    "                            l3_clamp_surprise[result_id] += np.squeeze(l3_E)\n",
    "                    else:\n",
    "                        l2_clamp_surprise[result_id] += np.squeeze(l2_E.mean(axis=1))\n",
    "                        if element == 'spikes':\n",
    "                            l1_clamp_surprise[result_id] += np.squeeze(l1_E.mean(axis=1))\n",
    "                            l3_clamp_surprise[result_id] += np.squeeze(l3_E.mean(axis=1))\n",
    "\n",
    "                    result_id += 1\n",
    "                    if result_id > 9999:\n",
    "                        break\n",
    "                        \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    if element == 'spikes':\n",
    "        return l1_clamp_surprise,l1_clamp_expected, l2_clamp_surprise,l2_clamp_expected, l3_clamp_surprise,l3_clamp_expected\n",
    "    else:\n",
    "        return l2_clamp_surprise, l2_clamp_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,element):\n",
    "    fig,ax=plt.subplots(1,1)\n",
    "    #_,bins2,_ = ax.hist(l2_diff_control.flatten(),bins=10,weights=[100/len(l2_diff_control.flatten())]*len(l2_diff_control.flatten()),label='Control')\n",
    "    #ax.hist(l2_diff_energy.flatten(),bins=10,weights=[100/len(l2_diff_energy.flatten())]*len(l2_diff_energy.flatten()),alpha=0.5,label='Energy')\n",
    "    # use static bins\n",
    "    palette = sns.color_palette(\"colorblind\")\n",
    "    pastel_blue = palette[0]\n",
    "    pastel_orange = palette[1]\n",
    "    \n",
    "    _,bins2,_ = ax.hist(l2_diff_control.flatten(),bins=[-0.05,-0.04,-0.03,-0.02,-0.01,0,0.01,0.02,0.03,0.04,0.05],weights=[100/len(l2_diff_control.flatten())]*len(l2_diff_control.flatten()),alpha=0.5,color=pastel_blue,label='Control')\n",
    "    ax.hist(l2_diff_energy.flatten(),bins=[-0.05,-0.04,-0.03,-0.02,-0.01,0,0.01,0.02,0.03,0.04,0.05],weights=[100/len(l2_diff_energy.flatten())]*len(l2_diff_energy.flatten()),alpha=0.5,color=pastel_orange,label='Energy')\n",
    "    \n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "    plt.legend(fontsize=20,loc='upper right')   \n",
    "    plt.ylabel('Percentage',fontsize=20)\n",
    "    plt.xlabel('MSD',fontsize=15)\n",
    "    plt.title('L2 {}'.format(element),fontsize=20)\n",
    "    plt.xticks(fontsize=17)\n",
    "    plt.yticks(fontsize=17)\n",
    "    plt.savefig('surprise_voltage_diff_{}_with_feedback.png'.format(element),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_time=True # value of each neuron is averaged over all timepoints\n",
    "element='apical'\n",
    "clamp_value = 1\n",
    "l2_diff_control_surprise,l2_diff_control_expected  = get_results(control_model,element,keep_time,seed,clamp_value)\n",
    "l2_diff_energy_surprise,l2_diff_energy_expected = get_results(energy_model,element,keep_time,seed,clamp_value)\n",
    "\n",
    "l2_diff_control = np.mean(l2_diff_control_expected-l2_diff_control_surprise,axis=1)\n",
    "l2_diff_energy = np.mean(l2_diff_energy_expected-l2_diff_energy_surprise,axis=1)\n",
    "\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_apical_L2_retry.npy',l2_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_apical_L2_retry.npy',l2_diff_energy)\n",
    "\n",
    "plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,'apical tuft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_time=True\n",
    "element='soma'\n",
    "l2_diff_control_surprise,l2_diff_control_expected  = get_results(control_model,element,keep_time,seed,clamp_value)\n",
    "l2_diff_energy_surprise,l2_diff_energy_expected = get_results(energy_model,element,keep_time,seed,clamp_value)\n",
    "\n",
    "l2_diff_control = np.mean(l2_diff_control_expected-l2_diff_control_surprise,axis=1)\n",
    "l2_diff_energy = np.mean(l2_diff_energy_expected-l2_diff_energy_surprise,axis=1)\n",
    "\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_soma_L2_with_feedback.npy',l2_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_soma_L2_with_feedback.npy',l2_diff_energy)\n",
    "\n",
    "plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,'soma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_time=True\n",
    "element='spikes'\n",
    "l1_diff_control_surprise,l1_diff_control_expected, l2_diff_control_surprise,l2_diff_control_expected, l3_diff_control_surprise,l3_diff_control_expected = get_results(control_model,element,keep_time,seed,clamp_value)\n",
    "l1_diff_energy_surprise,l1_diff_energy_expected, l2_diff_energy_surprise,l2_diff_energy_expected, l3_diff_energy_surprise,l3_diff_energy_expected = get_results(energy_model,element,keep_time,seed,clamp_value)\n",
    "\n",
    "l1_diff_control = np.mean(l1_diff_control_expected-l1_diff_control_surprise,axis=1)\n",
    "l1_diff_energy = np.mean(l1_diff_energy_expected-l1_diff_energy_surprise,axis=1)\n",
    "l2_diff_control = np.mean(l2_diff_control_expected-l2_diff_control_surprise,axis=1)\n",
    "l2_diff_energy = np.mean(l2_diff_energy_expected-l2_diff_energy_surprise,axis=1)\n",
    "l3_diff_control = np.mean(l3_diff_control_expected-l3_diff_control_surprise,axis=1)\n",
    "l3_diff_energy = np.mean(l3_diff_energy_expected-l3_diff_energy_surprise,axis=1)\n",
    "\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_spikes_L1_with_feedback.npy',l1_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_spikes_L1_with_feedback.npy',l1_diff_energy)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_spikes_L2_with_feedback.npy',l2_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_spikes_L2_with_feedback.npy',l2_diff_energy)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_control_spikes_L3_with_feedback.npy',l3_diff_control)\n",
    "np.save('graphs_intermediate_results\\\\surprise_voltage_diff_energy_spikes_L3_with_feedback.npy',l3_diff_energy)\n",
    "\n",
    "plot_voltage_diff_only_L2(l2_diff_control,l2_diff_energy,\"$\\delta$$R$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_time=True\n",
    "element='spikes'\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "X_axis = np.arange(3)\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "pastel_blue = palette[0]\n",
    "pastel_orange = palette[1]\n",
    "\n",
    "ax.bar(X_axis-0.2,[np.abs(l1_diff_control).mean(), np.abs(l2_diff_control).mean(), np.abs(l3_diff_control).mean()],0.4,color=pastel_blue,label=\"Control\")\n",
    "ax.bar(X_axis+0.2,[np.abs(l1_diff_energy).mean(), np.abs(l2_diff_energy).mean(), np.abs(l3_diff_energy).mean()],0.4,color=pastel_orange,label=\"Energy\")\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "labels=[\"1\",\"2\",\"3\"]\n",
    "plt.xticks(X_axis, labels, fontsize=20) \n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"Layer\",fontsize=20) \n",
    "plt.ylabel(r\"$\\delta$$R$\",fontsize=20) \n",
    "plt.title(r\"$\\delta$$R$ match vs. mismatch\",fontsize=20) \n",
    "plt.legend(fontsize=20) \n",
    "plt.savefig('graphs_intermediate_results\\\\surprise_voltage_diff_{}_average_with_feedback.png'.format('spikes'),bbox_inches='tight')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SNN_PC_Multicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
